{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da7baf0e",
      "metadata": {},
      "source": [
        "# Adversarial Attacks on Legal-Domain NER\n",
        "\n",
        "In this notebook, we evaluate the vulnerability of a Portuguese legal-domain NER model\n",
        "under *targeted adversarial attacks*. Unlike the robustness evaluation (Stage 2),\n",
        "which focused on broad perturbation scenarios, here we design **controlled,\n",
        "entity-aware attacks** to probe *where* and *why* the model fails.\n",
        "\n",
        "We consider both:\n",
        "- **Oracle-guided attacks**, using gold entity spans, and\n",
        "- **Prediction-guided attacks**, using the model’s own baseline predictions.\n",
        "\n",
        "This distinction allows us to assess not only worst-case vulnerability, but also\n",
        "realistic failure modes at inference time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eacfb7ab",
      "metadata": {},
      "source": [
        "## Oracle vs Prediction-Guided Attacks\n",
        "\n",
        "For each attack, we evaluate two variants:\n",
        "\n",
        "- **Oracle**: entity spans are derived from gold labels.\n",
        "- **Pred**: entity spans are derived from baseline model predictions.\n",
        "\n",
        "Oracle attacks represent an upper bound on adversarial effectiveness,\n",
        "while prediction-guided attacks reflect what is feasible without access\n",
        "to ground-truth annotations.\n",
        "\n",
        "Comparing both reveals how much attack success depends on *perfect*\n",
        "knowledge of entity boundaries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff9670f",
      "metadata": {},
      "source": [
        "## Why Word Insertion Requires a Separate Evaluation Protocol\n",
        "\n",
        "Word insertion attacks fundamentally alter sequence length and token alignment.\n",
        "As a result, standard token-aligned metrics (entity flip rate, span miss rate,\n",
        "confidence drop via projection) are **not well-defined**.\n",
        "\n",
        "To address this, we introduce a **true insertion evaluation protocol** that:\n",
        "- does NOT project predictions back to the original sequence,\n",
        "- measures **entity retention rate** in the attacked sequence, and\n",
        "- measures **confidence drop at the true post-insertion token positions**.\n",
        "\n",
        "This explains why some metrics appear as NaN for insertion attacks in the summary table.\n",
        "These NaNs indicate *non-applicability*, not missing computations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4ff2da",
      "metadata": {},
      "source": [
        "## Experimental Setup (Reproducibility)\n",
        "- **Dataset**: LeNER-Br validation subset (`val_subset`), first *N* examples (same as Stage 2 for comparability).\n",
        "- **Model**: fine-tuned Portuguese BERT for token classification (same checkpoint as Stages 2–3).\n",
        "- **Inference**: sliding-window over word-level tokens to avoid truncation:\n",
        "  - `MAX_LENGTH = {MAX_LENGTH}`, `STRIDE = {STRIDE}`\n",
        "  - logits for overlapping words are **averaged** before `argmax`.\n",
        "- **Randomness control**: fixed seeds for `random`, `numpy`, and `torch` (see cell below).\n",
        "- **Attack intensity**:\n",
        "  - char-typo probability `p = 0.5` inside entity spans\n",
        "  - insertion probability `p = 0.5` near span boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "id": "7e96667b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "from typing import Callable, Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score\n",
        "from seqeval.metrics.sequence_labeling import get_entities\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 4)\n",
        "\n",
        "SEED = 42\n",
        "EVAL_SIZE = 200\n",
        "MAX_LENGTH = 256\n",
        "STRIDE = 64\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "5c427c2e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\diogo\\Repositorios\\ner_smalllm_project\\.venv\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for peluz/lener_br contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/peluz/lener_br\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'tokens', 'ner_tags'],\n",
            "    num_rows: 200\n",
            "})\n",
            "Labels: ['O', 'B-ORGANIZACAO', 'I-ORGANIZACAO', 'B-PESSOA', 'I-PESSOA', 'B-TEMPO', 'I-TEMPO', 'B-LOCAL', 'I-LOCAL', 'B-LEGISLACAO', 'I-LEGISLACAO', 'B-JURISPRUDENCIA', 'I-JURISPRUDENCIA']\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "\n",
        "dataset_id = 'peluz/lener_br'\n",
        "hf_token = os.getenv('HF_TOKEN')\n",
        "lener = load_dataset(dataset_id, token=hf_token)\n",
        "\n",
        "ner_feature = lener['train'].features['ner_tags']\n",
        "label_list = ner_feature.feature.names\n",
        "id2label = {i: l for i, l in enumerate(label_list)}\n",
        "label2id = {l: i for i, l in enumerate(label_list)}\n",
        "\n",
        "val_subset = lener['validation'].select(range(EVAL_SIZE))\n",
        "print(val_subset)\n",
        "print('Labels:', label_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "id": "260ec483",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load fine-tuned model and tokenizer\n",
        "model_dir = r\"C:\\Users\\diogo\\Repositorios\\ner_smalllm_project\\notebooks\\models\\lenerbr_bert_base\"\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "num_labels = model.config.num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2474b609",
      "metadata": {},
      "source": [
        "## Helper utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9bf83c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_gold_labels(example) -> List[str]:\n",
        "    return [label_list[t] for t in example['ner_tags']]\n",
        "\n",
        "\n",
        "def get_spans(labels: List[str]) -> List[Tuple[str, int, int]]:\n",
        "    \"\"\"Return spans as (type, start, end) inclusive for BIO labels (defensive).\"\"\"\n",
        "    spans = []\n",
        "    ent_type = None\n",
        "    start = None\n",
        "\n",
        "    for i, tag in enumerate(labels):\n",
        "        if tag.startswith(\"B-\"):\n",
        "            # close previous span if open\n",
        "            if ent_type is not None:\n",
        "                spans.append((ent_type, start, i - 1))\n",
        "            ent_type = tag[2:]\n",
        "            start = i\n",
        "\n",
        "        elif tag.startswith(\"I-\"):\n",
        "            if ent_type is None:\n",
        "                continue\n",
        "\n",
        "            # If entity type changes inside span, close and start new (defensive)\n",
        "            if tag[2:] != ent_type:\n",
        "                spans.append((ent_type, start, i - 1))\n",
        "                ent_type = tag[2:]\n",
        "                start = i\n",
        "\n",
        "        else:  # \"O\"\n",
        "            if ent_type is not None:\n",
        "                spans.append((ent_type, start, i - 1))\n",
        "                ent_type = None\n",
        "                start = None\n",
        "\n",
        "    if ent_type is not None:\n",
        "        spans.append((ent_type, start, len(labels) - 1))\n",
        "\n",
        "    return spans\n",
        "\n",
        "\n",
        "def spans_from_gold(example) -> List[Tuple[str, int, int]]:\n",
        "    return get_spans(get_gold_labels(example))\n",
        "\n",
        "\n",
        "def spans_from_pred(tokens: List[str], pred_labels: List[str]) -> List[Tuple[str, int, int]]:\n",
        "    return get_spans(pred_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8abbb2b",
      "metadata": {},
      "source": [
        "## Metrics (Why these?)\n",
        "Beyond seqeval Precision/Recall/F1, we report **attack-specific diagnostics**:\n",
        "\n",
        "- **Entity flip rate**: among gold entity tokens that were correct at baseline, how often the attack turns them wrong.\n",
        "- **Span miss rate (strict)**: fraction of gold spans not recovered exactly as (TYPE, start, end).\n",
        "- **Span token error rate**: fraction of gold spans where at least one token label inside the span is wrong.\n",
        "- **Confidence drop (gold/pred)**: average logit drop for the gold class or the baseline predicted class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2354d3",
      "metadata": {},
      "source": [
        "## Sliding-window prediction (no truncation mismatches)\n",
        "Overlapping windows with stride cover long sequences; logits for shared words are averaged before argmax.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887245dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity check lengths: 211 (211, 13)\n"
          ]
        }
      ],
      "source": [
        "def predict_word_logits(tokens: List[str]) -> np.ndarray:\n",
        "    \"\"\"Aggregate logits over sliding windows. Returns (n_words, num_labels).\"\"\"\n",
        "    model.eval()  # disables dropout for stable/reproducible logits\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        tokens,\n",
        "        is_split_into_words=True,\n",
        "        return_overflowing_tokens=True,\n",
        "        stride=STRIDE,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=None,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "    n_words = len(tokens)\n",
        "    agg = np.zeros((n_words, num_labels), dtype=np.float32)\n",
        "    counts = np.zeros(n_words, dtype=np.float32)\n",
        "\n",
        "    for i in range(len(encoding[\"input_ids\"])):\n",
        "        input_ids = torch.tensor(encoding[\"input_ids\"][i]).unsqueeze(0).to(device)\n",
        "        attention_mask = (\n",
        "            torch.tensor(encoding[\"attention_mask\"][i]).unsqueeze(0).to(device)\n",
        "        )\n",
        "        word_ids = encoding.word_ids(i)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        logits = outputs.logits.squeeze(0).cpu().numpy()\n",
        "\n",
        "        for pos, wid in enumerate(word_ids):\n",
        "            if wid is None:\n",
        "                continue\n",
        "            agg[wid] += logits[pos]\n",
        "            counts[wid] += 1\n",
        "\n",
        "    if (counts == 0).any():\n",
        "        missing = np.where(counts == 0)[0].tolist()\n",
        "        raise ValueError(f\"Missing logits for word indices: {missing}\")\n",
        "\n",
        "    agg /= counts[:, None]  # average across overlapping windows\n",
        "    return agg\n",
        "\n",
        "\n",
        "def predict_word_labels(tokens: List[str]) -> List[str]:\n",
        "    logits = predict_word_logits(tokens)\n",
        "    pred_ids = logits.argmax(axis=1)\n",
        "    return [label_list[i] for i in pred_ids]\n",
        "\n",
        "\n",
        "idx_long = max(range(len(val_subset)), key=lambda i: len(val_subset[i][\"tokens\"])) \n",
        "long_example = val_subset[idx_long][\"tokens\"] \n",
        "logits_test = predict_word_logits(long_example) \n",
        "print(\"Sanity check lengths:\", len(long_example), logits_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0240235a",
      "metadata": {},
      "source": [
        "## Attacks (oracle and pred-guided variants)\n",
        "Substitution attacks preserve length; insertion changes length but uses mapping for evaluation.\n",
        "\n",
        "### Note on the boundary attack design\n",
        "Boundary perturbations replace punctuation near entity spans with the tokenizer's `[MASK]` token (when available).\n",
        "This keeps length constant and avoids introducing an artificial strong token (e.g., `\"__\"`), but it can also make\n",
        "the attack **less destructive** than deleting punctuation entirely, because `[MASK]` is a familiar BERT token.\n",
        "This is intentional here: we isolate boundary disruption while keeping the input format valid. Consistent with this conservative design, boundary attacks show only a small F1 drop (≈0–1.6 p.p.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "1ebb1a2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "DISTRACTORS = ['xxx', 'lorem', 'teste', 'ruido']\n",
        "SYN_MAP = {\n",
        "    'TRIBUNAL': 'CORTE',\n",
        "    'MINISTRO': 'AUTORIDADE',\n",
        "    'LEI': 'NORMA',\n",
        "    'ACÓRDÃO': 'DECISAO',\n",
        "    'JUIZ': 'MAGISTRADO',\n",
        "}\n",
        "\n",
        "\n",
        "def mutate_token(token: str) -> str:\n",
        "    if len(token) <= 1:\n",
        "        return token\n",
        "    ops = ['swap', 'replace', 'delete']\n",
        "    op = random.choice(ops)\n",
        "    if op == 'swap' and len(token) >= 3:\n",
        "        i = random.randint(1, len(token) - 2)\n",
        "        chars = list(token)\n",
        "        chars[i], chars[i + 1] = chars[i + 1], chars[i]\n",
        "        return ''.join(chars)\n",
        "    if op == 'delete' and len(token) > 1:\n",
        "        i = random.randint(0, len(token) - 1)\n",
        "        mutated = token[:i] + token[i + 1 :]\n",
        "        return mutated or token\n",
        "    i = random.randint(0, len(token) - 1)\n",
        "    return token[:i] + random.choice(string.ascii_lowercase) + token[i + 1 :]\n",
        "\n",
        "\n",
        "def span_indices(spans: List[Tuple[str, int, int]]) -> set:\n",
        "    idxs = set()\n",
        "    for _, s, e in spans:\n",
        "        idxs.update(range(s, e + 1))\n",
        "    return idxs\n",
        "\n",
        "\n",
        "def attack_char_typo(tokens: List[str], spans: List[Tuple[str, int, int]], p: float = 0.5) -> Tuple[List[str], None]:\n",
        "    targeted = span_indices(spans)\n",
        "    attacked = []\n",
        "    for i, tok in enumerate(tokens):\n",
        "        if i in targeted and random.random() < p:\n",
        "            attacked.append(mutate_token(tok))\n",
        "        else:\n",
        "            attacked.append(tok)\n",
        "    return attacked, None\n",
        "\n",
        "\n",
        "def attack_boundary(\n",
        "    tokens: List[str], spans: List[Tuple[str, int, int]]\n",
        ") -> Tuple[List[str], None]:\n",
        "    # Replace boundary punctuation near entities with a neutral placeholder (length preserved).\n",
        "    # Using [MASK] (when available) avoids creating a new artificial \"strong token\" like \"__\".\n",
        "    placeholder = tokenizer.mask_token or \"_\"\n",
        "\n",
        "    targeted = span_indices(spans)\n",
        "    attacked = list(tokens)\n",
        "\n",
        "    for i, tok in enumerate(tokens):\n",
        "        if tok in {\"(\", \")\", \",\", \".\"}:\n",
        "            neighbor_entity = (\n",
        "                (i > 0 and (i - 1) in targeted)\n",
        "                or (i + 1 < len(tokens) and (i + 1) in targeted)\n",
        "                or (i in targeted)\n",
        "            )\n",
        "            if neighbor_entity:\n",
        "                attacked[i] = placeholder\n",
        "\n",
        "    return attacked, None\n",
        "\n",
        "\n",
        "def attack_context_distractors(tokens: List[str], spans: List[Tuple[str, int, int]]) -> Tuple[List[str], None]:\n",
        "    # Replace tokens immediately before/after spans with distractors (length preserved).\n",
        "    attacked = list(tokens)\n",
        "    for _, s, e in spans:\n",
        "        if s - 1 >= 0:\n",
        "            attacked[s - 1] = random.choice(DISTRACTORS)\n",
        "        if e + 1 < len(tokens):\n",
        "            attacked[e + 1] = random.choice(DISTRACTORS)\n",
        "    return attacked, None\n",
        "\n",
        "\n",
        "def attack_synonym(tokens: List[str], spans: List[Tuple[str, int, int]]) -> Tuple[List[str], None]:\n",
        "    targeted = span_indices(spans)\n",
        "    attacked = []\n",
        "    for i, tok in enumerate(tokens):\n",
        "        key = tok.upper()\n",
        "        if i in targeted and key in SYN_MAP:\n",
        "            repl = SYN_MAP[key]\n",
        "            attacked.append(repl.title() if tok.istitle() else repl.lower())\n",
        "        else:\n",
        "            attacked.append(tok)\n",
        "    return attacked, None\n",
        "\n",
        "\n",
        "def apply_insertion_with_mapping(\n",
        "    tokens: List[str],\n",
        "    spans: List[Tuple[str, int, int]],\n",
        "    p: float = 0.5,\n",
        "    distractors: List[str] = None,\n",
        ") -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    Inserts distractors near entity spans.\n",
        "    Returns:\n",
        "      attacked_tokens: tokens with insertions\n",
        "      mapping: for each ORIGINAL token index i, mapping[i] = position of that token in attacked_tokens\n",
        "               (so you can locate where original words landed)\n",
        "    \"\"\"\n",
        "    if distractors is None:\n",
        "        distractors = [\"xxx\", \"lorem\", \"teste\", \"ruido\"]\n",
        "\n",
        "    span_starts = {s for _, s, _ in spans}\n",
        "    span_ends = {e for _, _, e in spans}\n",
        "\n",
        "    attacked = []\n",
        "    mapping = []\n",
        "\n",
        "    for idx, tok in enumerate(tokens):\n",
        "        if idx in span_starts and random.random() < p:\n",
        "            attacked.append(random.choice(distractors))\n",
        "\n",
        "        attacked.append(tok)\n",
        "        mapping.append(len(attacked) - 1)\n",
        "\n",
        "        if idx in span_ends and random.random() < p:\n",
        "            attacked.append(random.choice(distractors))\n",
        "\n",
        "    return attacked, mapping\n",
        "\n",
        "\n",
        "def project_predictions_to_original(pred_labels: List[str], mapping: List[int]) -> List[str]:\n",
        "    return [pred_labels[m] for m in mapping]\n",
        "\n",
        "\n",
        "def project_logits_to_original(logits: np.ndarray, mapping: List[int]) -> np.ndarray:\n",
        "    return logits[mapping]\n",
        "\n",
        "\n",
        "def attack_insert(tokens: List[str], spans: List[Tuple[str, int, int]], p: float = 0.5) -> Tuple[List[str], List[int]]:\n",
        "    return apply_insertion_with_mapping(tokens, spans, p=p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba1d7ab",
      "metadata": {},
      "source": [
        "## Evaluation helpers\n",
        "Metrics: PRF, per-type F1, flip rate, span break, confidence drops (gold/pred).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f90ff901",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_per_type_f1(\n",
        "    golds: List[List[str]], preds: List[List[str]]\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute per-entity-type F1 scores using seqeval entity spans.\n",
        "    Entity types are derived from labels (without BIO prefixes).\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract canonical entity types (e.g., PESSOA, LOCAL, TEMPO)\n",
        "    entity_types = sorted({lbl.split(\"-\", 1)[1] for lbl in label_list if lbl != \"O\"})\n",
        "\n",
        "    counts = {t: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for t in entity_types}\n",
        "\n",
        "    for g_seq, p_seq in zip(golds, preds):\n",
        "        g_ents = set(get_entities(g_seq))  # (TYPE, start, end)\n",
        "        p_ents = set(get_entities(p_seq))\n",
        "\n",
        "        for ent in g_ents & p_ents:\n",
        "            counts[ent[0]][\"tp\"] += 1\n",
        "\n",
        "        for ent in p_ents - g_ents:\n",
        "            counts[ent[0]][\"fp\"] += 1\n",
        "\n",
        "        for ent in g_ents - p_ents:\n",
        "            counts[ent[0]][\"fn\"] += 1\n",
        "\n",
        "    f1s = {}\n",
        "    for t, c in counts.items():\n",
        "        tp, fp, fn = c[\"tp\"], c[\"fp\"], c[\"fn\"]\n",
        "        prec = tp / (tp + fp) if (tp + fp) else 0.0\n",
        "        rec = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "        f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) else 0.0\n",
        "        f1s[f\"f1_{t}\"] = f1\n",
        "\n",
        "    return f1s\n",
        "\n",
        "\n",
        "def entity_retention_rate_true_insertion(\n",
        "    gold_labels: List[str],\n",
        "    attacked_pred_labels: List[str],\n",
        "    mapping: List[int],\n",
        "    window: int = 8,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Measures how many GOLD spans are still recovered after insertion, without projecting labels back.\n",
        "    We search for a matching span (same type and same length) near the mapped positions.\n",
        "\n",
        "    mapping: original_index -> attacked_index (position where that original token appears)\n",
        "    window: how far left/right we search around mapped region\n",
        "    \"\"\"\n",
        "    gold_spans = get_spans(gold_labels)\n",
        "    if not gold_spans:\n",
        "        return 0.0\n",
        "\n",
        "    recovered = 0\n",
        "\n",
        "    for ent_type, s, e in gold_spans:\n",
        "        # mapped interval in attacked sequence\n",
        "        s2 = mapping[s]\n",
        "        e2 = mapping[e]\n",
        "        span_len = e - s + 1\n",
        "\n",
        "        # search region (clamped)\n",
        "        left = max(0, s2 - window)\n",
        "        right = min(len(attacked_pred_labels) - 1, e2 + window)\n",
        "\n",
        "        found = False\n",
        "        # try all possible start positions in [left, right-span_len+1]\n",
        "        for start in range(left, right - span_len + 1):\n",
        "            end = start + span_len - 1\n",
        "            # check exact BIO pattern match inside that slice\n",
        "            # We expect: B-<type> then I-<type>... for the rest\n",
        "            slice_labels = attacked_pred_labels[start : end + 1]\n",
        "            if not slice_labels:\n",
        "                continue\n",
        "\n",
        "            if slice_labels[0] == f\"B-{ent_type}\" and all(\n",
        "                lab == f\"I-{ent_type}\" for lab in slice_labels[1:]\n",
        "            ):\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        if found:\n",
        "            recovered += 1\n",
        "\n",
        "    return recovered / len(gold_spans)\n",
        "\n",
        "\n",
        "def compute_entity_flip_rate(golds, base_preds, attack_preds) -> float:\n",
        "    total = 0\n",
        "    flips = 0\n",
        "    for g_seq, b_seq, a_seq in zip(golds, base_preds, attack_preds):\n",
        "        for g, b, a in zip(g_seq, b_seq, a_seq):\n",
        "            if g == 'O':\n",
        "                continue\n",
        "            total += 1\n",
        "            if b == g and a != g:\n",
        "                flips += 1\n",
        "    return flips / total if total else 0.0\n",
        "\n",
        "\n",
        "def span_miss_rate(golds: List[List[str]], preds: List[List[str]]) -> float:\n",
        "    \"\"\"\n",
        "    Fraction of gold spans that are NOT recovered as an exact (type,start,end) span in predictions.\n",
        "    This is strict span-level matching.\n",
        "    \"\"\"\n",
        "    broken = 0\n",
        "    total = 0\n",
        "    for g_seq, p_seq in zip(golds, preds):\n",
        "        gold_spans = set(get_spans(g_seq))  # (TYPE, start, end)\n",
        "        pred_spans = set(get_spans(p_seq))\n",
        "        total += len(gold_spans)\n",
        "        for span in gold_spans:\n",
        "            if span not in pred_spans:\n",
        "                broken += 1\n",
        "    return broken / total if total else 0.0\n",
        "\n",
        "\n",
        "def span_token_error_rate(golds: List[List[str]], preds: List[List[str]]) -> float:\n",
        "    \"\"\"\n",
        "    Fraction of gold spans for which at least one token inside the gold span\n",
        "    has a different label in the prediction (token-level strictness inside spans).\n",
        "    \"\"\"\n",
        "    broken = 0\n",
        "    total = 0\n",
        "    for g_seq, p_seq in zip(golds, preds):\n",
        "        gold_spans = get_spans(g_seq)\n",
        "        total += len(gold_spans)\n",
        "        for _, s, e in gold_spans:\n",
        "            # If any token inside span differs -> break\n",
        "            if any(p_seq[i] != g_seq[i] for i in range(s, e + 1)):\n",
        "                broken += 1\n",
        "    return broken / total if total else 0.0\n",
        "\n",
        "\n",
        "def compute_confidence_drop_gold(golds, base_logits, attack_logits) -> float:\n",
        "    deltas = []\n",
        "    for g_seq, b_log, a_log in zip(golds, base_logits, attack_logits):\n",
        "        for g, b_row, a_row in zip(g_seq, b_log, a_log):\n",
        "            if g == 'O':\n",
        "                continue\n",
        "            gid = label2id[g]\n",
        "            deltas.append(b_row[gid] - a_row[gid])\n",
        "    return float(np.mean(deltas)) if deltas else 0.0\n",
        "\n",
        "\n",
        "def conf_drop_gold_true_insertion(\n",
        "    gold_labels: List[str],\n",
        "    base_logits_original: np.ndarray,  # shape: (n_words_original, num_labels)\n",
        "    attacked_logits: np.ndarray,  # shape: (n_words_attacked, num_labels)\n",
        "    mapping: List[int],\n",
        "    label2id: dict,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Average drop in the GOLD class logit for gold != 'O', comparing:\n",
        "      base: logits at original positions\n",
        "      attacked: logits at mapped positions (where the original word landed after insertion)\n",
        "    \"\"\"\n",
        "    drops = []\n",
        "    for i, g in enumerate(gold_labels):\n",
        "        if g == \"O\":\n",
        "            continue\n",
        "        gid = label2id[g]\n",
        "        j = mapping[i]\n",
        "        drops.append(float(base_logits_original[i, gid] - attacked_logits[j, gid]))\n",
        "    return float(np.mean(drops)) if drops else 0.0\n",
        "\n",
        "\n",
        "def compute_confidence_drop_pred(golds, base_logits, attack_logits) -> float:\n",
        "    deltas = []\n",
        "    for g_seq, b_log, a_log in zip(golds, base_logits, attack_logits):\n",
        "        for g, b_row, a_row in zip(g_seq, b_log, a_log):\n",
        "            if g == 'O':\n",
        "                continue\n",
        "            pid = int(np.argmax(b_row))\n",
        "            deltas.append(b_row[pid] - a_row[pid])\n",
        "    return float(np.mean(deltas)) if deltas else 0.0\n",
        "\n",
        "\n",
        "def run_insertion_attack(\n",
        "    dataset_split,\n",
        "    p: float,\n",
        "    span_source: str,\n",
        "    baseline_preds: List[List[str]],\n",
        "    base_logits_list: List[np.ndarray], \n",
        "):\n",
        "    \"\"\"\n",
        "    Computes:\n",
        "      - Precision / Recall / F1 on attacked sequence\n",
        "      - Entity retention rate\n",
        "      - Confidence drop on GOLD labels (true insertion)\n",
        "    \"\"\"\n",
        "\n",
        "    all_golds_attacked = []\n",
        "    all_preds_attacked = []\n",
        "\n",
        "    retention_scores = []\n",
        "    conf_drops = []\n",
        "\n",
        "    for idx, ex in enumerate(dataset_split):\n",
        "        tokens = ex[\"tokens\"]\n",
        "        gold = get_gold_labels(ex)\n",
        "\n",
        "        # select spans\n",
        "        if span_source == \"oracle\":\n",
        "            spans = spans_from_gold(ex)\n",
        "        elif span_source == \"pred\":\n",
        "            spans = spans_from_pred(tokens, baseline_preds[idx])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown span_source: {span_source}\")\n",
        "\n",
        "        # insertion + mapping\n",
        "        attacked_tokens, mapping = apply_insertion_with_mapping(tokens, spans, p=p)\n",
        "\n",
        "        # logits\n",
        "        base_logits = base_logits_list[idx]  # (n_orig, C)\n",
        "        attacked_logits = predict_word_logits(attacked_tokens)  # (n_attacked, C)\n",
        "\n",
        "        attacked_pred_ids = attacked_logits.argmax(axis=1)\n",
        "        attacked_pred_labels = [label_list[i] for i in attacked_pred_ids]\n",
        "\n",
        "        # metrics\n",
        "        retention = entity_retention_rate_true_insertion(\n",
        "            gold_labels=gold,\n",
        "            attacked_pred_labels=attacked_pred_labels,\n",
        "            mapping=mapping,\n",
        "            window=8,\n",
        "        )\n",
        "        retention_scores.append(retention)\n",
        "\n",
        "        conf_drop = conf_drop_gold_true_insertion(\n",
        "            gold_labels=gold,\n",
        "            base_logits_original=base_logits,\n",
        "            attacked_logits=attacked_logits,\n",
        "            mapping=mapping,\n",
        "            label2id=label2id,\n",
        "        )\n",
        "        conf_drops.append(conf_drop)\n",
        "\n",
        "        # PRF on attacked sequence\n",
        "        # build GOLD labels expanded to attacked space\n",
        "        gold_attacked = [\"O\"] * len(attacked_pred_labels)\n",
        "        for i, g in enumerate(gold):\n",
        "            gold_attacked[mapping[i]] = g\n",
        "\n",
        "        all_golds_attacked.append(gold_attacked)\n",
        "        all_preds_attacked.append(attacked_pred_labels)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(all_golds_attacked, all_preds_attacked),\n",
        "        \"recall\": recall_score(all_golds_attacked, all_preds_attacked),\n",
        "        \"f1\": f1_score(all_golds_attacked, all_preds_attacked),\n",
        "        \"entity_retention_rate\": (\n",
        "            float(np.mean(retention_scores)) if retention_scores else 0.0\n",
        "        ),\n",
        "        \"conf_drop_gold_true_insertion\": (\n",
        "            float(np.mean(conf_drops)) if conf_drops else 0.0\n",
        "        ),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_predictions(dataset_split, attack_fn: Callable = None, span_source: str = 'oracle', baseline_preds=None, insertion: bool = False):\n",
        "    golds, preds, logits_list = [], [], []\n",
        "    original_tokens, attacked_tokens = [], []\n",
        "    mappings = []\n",
        "    for idx, ex in enumerate(dataset_split):\n",
        "        tokens = ex['tokens']\n",
        "        gold = get_gold_labels(ex)\n",
        "\n",
        "        if attack_fn is None:\n",
        "            attacked = tokens\n",
        "            mapping = None\n",
        "        else:\n",
        "            if span_source == 'oracle':\n",
        "                spans = spans_from_gold(ex)\n",
        "            elif span_source == 'pred':\n",
        "                if baseline_preds is None:\n",
        "                    raise ValueError('Pred-guided attacks require baseline predictions.')\n",
        "                spans = spans_from_pred(tokens, baseline_preds[idx])\n",
        "            else:\n",
        "                raise ValueError(f'Unknown span_source: {span_source}')\n",
        "            attacked, mapping = attack_fn(tokens, spans)\n",
        "\n",
        "        logits = predict_word_logits(attacked)\n",
        "        pred_ids_full = logits.argmax(axis=1)\n",
        "        pred_labels_full = [label_list[i] for i in pred_ids_full]\n",
        "\n",
        "        if insertion and mapping is not None:\n",
        "            pred_labels = project_predictions_to_original(pred_labels_full, mapping)\n",
        "            logits_proj = project_logits_to_original(logits, mapping)\n",
        "        else:\n",
        "            pred_labels = pred_labels_full\n",
        "            logits_proj = logits\n",
        "\n",
        "        assert len(pred_labels) == len(gold), f'Length mismatch: pred={len(pred_labels)} gold={len(gold)}'\n",
        "\n",
        "        golds.append(gold)\n",
        "        preds.append(pred_labels)\n",
        "        logits_list.append(logits_proj)\n",
        "        original_tokens.append(tokens)\n",
        "        attacked_tokens.append(attacked)\n",
        "        mappings.append(mapping)\n",
        "    return original_tokens, attacked_tokens, golds, preds, logits_list, mappings\n",
        "\n",
        "\n",
        "def evaluate_attack(name: str, golds, preds, base_preds, base_logits, attack_logits, baseline_f1: float) -> Dict[str, float]:\n",
        "    metrics = {\n",
        "        \"attack\": name,\n",
        "        \"precision\": precision_score(golds, preds),\n",
        "        \"recall\": recall_score(golds, preds),\n",
        "        \"f1\": f1_score(golds, preds),\n",
        "        \"entity_flip_rate\": compute_entity_flip_rate(golds, base_preds, preds),\n",
        "        \"span_miss_rate\": span_miss_rate(golds, preds),\n",
        "        \"span_token_error_rate\": span_token_error_rate(golds, preds),\n",
        "        \"conf_drop_gold\": compute_confidence_drop_gold(\n",
        "            golds, base_logits, attack_logits\n",
        "        ),\n",
        "        \"conf_drop_pred\": compute_confidence_drop_pred(\n",
        "            golds, base_logits, attack_logits\n",
        "        ),\n",
        "    }\n",
        "    metrics['delta_f1'] = metrics['f1'] - baseline_f1\n",
        "    metrics.update(compute_per_type_f1(golds, preds))\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84696c5",
      "metadata": {},
      "source": [
        "## Run baseline (for pred-guided spans and confidence reference)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb5044e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline F1: 0.8625730994152047\n"
          ]
        }
      ],
      "source": [
        "base_orig, base_tokens, golds, base_preds, base_logits, _ = run_predictions(val_subset)\n",
        "baseline_f1 = f1_score(golds, base_preds)\n",
        "print('Baseline F1:', baseline_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "285a5005",
      "metadata": {},
      "source": [
        "## Evaluate substitution attacks (oracle and pred-guided)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "bf5025a3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>entity_flip_rate</th>\n",
              "      <th>span_miss_rate</th>\n",
              "      <th>span_token_error_rate</th>\n",
              "      <th>conf_drop_gold</th>\n",
              "      <th>conf_drop_pred</th>\n",
              "      <th>delta_f1</th>\n",
              "      <th>f1_JURISPRUDENCIA</th>\n",
              "      <th>f1_LEGISLACAO</th>\n",
              "      <th>f1_LOCAL</th>\n",
              "      <th>f1_ORGANIZACAO</th>\n",
              "      <th>f1_PESSOA</th>\n",
              "      <th>f1_TEMPO</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>char_typo_oracle</th>\n",
              "      <td>0.705357</td>\n",
              "      <td>0.718182</td>\n",
              "      <td>0.711712</td>\n",
              "      <td>0.151232</td>\n",
              "      <td>0.287879</td>\n",
              "      <td>0.278788</td>\n",
              "      <td>0.996056</td>\n",
              "      <td>1.012437</td>\n",
              "      <td>-0.150861</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.694064</td>\n",
              "      <td>0.844444</td>\n",
              "      <td>0.945055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_typo_pred</th>\n",
              "      <td>0.740299</td>\n",
              "      <td>0.751515</td>\n",
              "      <td>0.745865</td>\n",
              "      <td>0.112150</td>\n",
              "      <td>0.248485</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.865386</td>\n",
              "      <td>0.942909</td>\n",
              "      <td>-0.116708</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.684444</td>\n",
              "      <td>0.873563</td>\n",
              "      <td>0.989247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boundary_oracle</th>\n",
              "      <td>0.812849</td>\n",
              "      <td>0.881818</td>\n",
              "      <td>0.845930</td>\n",
              "      <td>0.006797</td>\n",
              "      <td>0.118182</td>\n",
              "      <td>0.103030</td>\n",
              "      <td>0.030644</td>\n",
              "      <td>0.046220</td>\n",
              "      <td>-0.016643</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.949367</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.824034</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boundary_pred</th>\n",
              "      <td>0.838617</td>\n",
              "      <td>0.881818</td>\n",
              "      <td>0.859675</td>\n",
              "      <td>0.006797</td>\n",
              "      <td>0.118182</td>\n",
              "      <td>0.103030</td>\n",
              "      <td>0.038955</td>\n",
              "      <td>0.038127</td>\n",
              "      <td>-0.002898</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.949367</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.838428</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_distractors_oracle</th>\n",
              "      <td>0.775244</td>\n",
              "      <td>0.721212</td>\n",
              "      <td>0.747253</td>\n",
              "      <td>0.121495</td>\n",
              "      <td>0.278788</td>\n",
              "      <td>0.275758</td>\n",
              "      <td>0.799218</td>\n",
              "      <td>0.746208</td>\n",
              "      <td>-0.115320</td>\n",
              "      <td>0.566038</td>\n",
              "      <td>0.924051</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.955556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_distractors_pred</th>\n",
              "      <td>0.784983</td>\n",
              "      <td>0.696970</td>\n",
              "      <td>0.738363</td>\n",
              "      <td>0.127443</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.888147</td>\n",
              "      <td>0.850695</td>\n",
              "      <td>-0.124210</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.930818</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.804878</td>\n",
              "      <td>0.906977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>synonym_oracle</th>\n",
              "      <td>0.829545</td>\n",
              "      <td>0.884848</td>\n",
              "      <td>0.856305</td>\n",
              "      <td>0.005947</td>\n",
              "      <td>0.115152</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.052635</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>-0.006268</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.824034</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>synonym_pred</th>\n",
              "      <td>0.829545</td>\n",
              "      <td>0.884848</td>\n",
              "      <td>0.856305</td>\n",
              "      <td>0.005947</td>\n",
              "      <td>0.115152</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.044629</td>\n",
              "      <td>0.045067</td>\n",
              "      <td>-0.006268</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.824034</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            precision    recall        f1  entity_flip_rate  \\\n",
              "attack                                                                        \n",
              "char_typo_oracle             0.705357  0.718182  0.711712          0.151232   \n",
              "char_typo_pred               0.740299  0.751515  0.745865          0.112150   \n",
              "boundary_oracle              0.812849  0.881818  0.845930          0.006797   \n",
              "boundary_pred                0.838617  0.881818  0.859675          0.006797   \n",
              "context_distractors_oracle   0.775244  0.721212  0.747253          0.121495   \n",
              "context_distractors_pred     0.784983  0.696970  0.738363          0.127443   \n",
              "synonym_oracle               0.829545  0.884848  0.856305          0.005947   \n",
              "synonym_pred                 0.829545  0.884848  0.856305          0.005947   \n",
              "\n",
              "                            span_miss_rate  span_token_error_rate  \\\n",
              "attack                                                              \n",
              "char_typo_oracle                  0.287879               0.278788   \n",
              "char_typo_pred                    0.248485               0.227273   \n",
              "boundary_oracle                   0.118182               0.103030   \n",
              "boundary_pred                     0.118182               0.103030   \n",
              "context_distractors_oracle        0.278788               0.275758   \n",
              "context_distractors_pred          0.303030               0.300000   \n",
              "synonym_oracle                    0.115152               0.100000   \n",
              "synonym_pred                      0.115152               0.100000   \n",
              "\n",
              "                            conf_drop_gold  conf_drop_pred  delta_f1  \\\n",
              "attack                                                                 \n",
              "char_typo_oracle                  0.996056        1.012437 -0.150861   \n",
              "char_typo_pred                    0.865386        0.942909 -0.116708   \n",
              "boundary_oracle                   0.030644        0.046220 -0.016643   \n",
              "boundary_pred                     0.038955        0.038127 -0.002898   \n",
              "context_distractors_oracle        0.799218        0.746208 -0.115320   \n",
              "context_distractors_pred          0.888147        0.850695 -0.124210   \n",
              "synonym_oracle                    0.052635        0.038710 -0.006268   \n",
              "synonym_pred                      0.044629        0.045067 -0.006268   \n",
              "\n",
              "                            f1_JURISPRUDENCIA  f1_LEGISLACAO  f1_LOCAL  \\\n",
              "attack                                                                   \n",
              "char_typo_oracle                     0.500000       0.797101  0.250000   \n",
              "char_typo_pred                       0.584615       0.810811  0.340426   \n",
              "boundary_oracle                      0.718750       0.949367  0.444444   \n",
              "boundary_pred                        0.718750       0.949367  0.444444   \n",
              "context_distractors_oracle           0.566038       0.924051  0.478261   \n",
              "context_distractors_pred             0.518519       0.930818  0.347826   \n",
              "synonym_oracle                       0.781250       0.923077  0.560000   \n",
              "synonym_pred                         0.781250       0.923077  0.560000   \n",
              "\n",
              "                            f1_ORGANIZACAO  f1_PESSOA  f1_TEMPO  \n",
              "attack                                                           \n",
              "char_typo_oracle                  0.694064   0.844444  0.945055  \n",
              "char_typo_pred                    0.684444   0.873563  0.989247  \n",
              "boundary_oracle                   0.824034   0.894118  1.000000  \n",
              "boundary_pred                     0.838428   0.974359  1.000000  \n",
              "context_distractors_oracle        0.608696   0.795181  0.955556  \n",
              "context_distractors_pred          0.632653   0.804878  0.906977  \n",
              "synonym_oracle                    0.824034   0.894118  1.000000  \n",
              "synonym_pred                      0.824034   0.894118  1.000000  "
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attack_specs = [\n",
        "    ('char_typo_oracle', attack_char_typo, 'oracle', False),\n",
        "    ('char_typo_pred', attack_char_typo, 'pred', False),\n",
        "    ('boundary_oracle', attack_boundary, 'oracle', False),\n",
        "    ('boundary_pred', attack_boundary, 'pred', False),\n",
        "    ('context_distractors_oracle', attack_context_distractors, 'oracle', False),\n",
        "    ('context_distractors_pred', attack_context_distractors, 'pred', False),\n",
        "    ('synonym_oracle', attack_synonym, 'oracle', False),\n",
        "    ('synonym_pred', attack_synonym, 'pred', False),\n",
        "]\n",
        "\n",
        "results = []\n",
        "attack_runs = {'baseline': {'tokens': base_tokens, 'preds': base_preds, 'logits': base_logits}}\n",
        "\n",
        "for name, fn, span_source, insertion in attack_specs:\n",
        "    atk_orig, atk_tokens, golds_tmp, preds_tmp, logits_tmp, _ = run_predictions(\n",
        "        val_subset,\n",
        "        attack_fn=fn,\n",
        "        span_source=span_source,\n",
        "        baseline_preds=base_preds,\n",
        "        insertion=insertion,\n",
        "    )\n",
        "    attack_runs[name] = {'tokens': atk_tokens, 'preds': preds_tmp, 'logits': logits_tmp}\n",
        "    metrics = evaluate_attack(name, golds_tmp, preds_tmp, base_preds, base_logits, logits_tmp, baseline_f1)\n",
        "    results.append(metrics)\n",
        "\n",
        "results_df = pd.DataFrame(results).set_index('attack')\n",
        "results_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "160eff2a",
      "metadata": {},
      "source": [
        "## How to Read the Results Table\n",
        "\n",
        "- **delta_f1**: change relative to baseline performance.\n",
        "- **entity_flip_rate**: fraction of gold entity tokens flipped from correct to incorrect.\n",
        "- **span_miss_rate**: fraction of gold spans not exactly recovered.\n",
        "- **span_token_error_rate**: fraction of spans with at least one incorrect token.\n",
        "- **conf_drop_gold / conf_drop_pred**: average logit drop under attack.\n",
        "- **entity_retention_rate** (insertion only): proportion of gold entities still recovered in the attacked sequence without projection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27dfcb30",
      "metadata": {},
      "source": [
        "## Insertion attack (length-changing with mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d095b3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>delta_f1</th>\n",
              "      <th>entity_flip_rate</th>\n",
              "      <th>span_miss_rate</th>\n",
              "      <th>span_token_error_rate</th>\n",
              "      <th>conf_drop_gold</th>\n",
              "      <th>conf_drop_pred</th>\n",
              "      <th>entity_retention_rate</th>\n",
              "      <th>conf_drop_gold_true_insertion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>insert_true_oracle</th>\n",
              "      <td>0.784091</td>\n",
              "      <td>0.836364</td>\n",
              "      <td>0.809384</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.432628</td>\n",
              "      <td>0.102404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insert_true_pred</th>\n",
              "      <td>0.810345</td>\n",
              "      <td>0.839286</td>\n",
              "      <td>0.824561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.441705</td>\n",
              "      <td>0.065894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    precision    recall        f1  delta_f1  entity_flip_rate  \\\n",
              "attack                                                                          \n",
              "insert_true_oracle   0.784091  0.836364  0.809384       NaN               NaN   \n",
              "insert_true_pred     0.810345  0.839286  0.824561       NaN               NaN   \n",
              "\n",
              "                    span_miss_rate  span_token_error_rate  conf_drop_gold  \\\n",
              "attack                                                                      \n",
              "insert_true_oracle             NaN                    NaN             NaN   \n",
              "insert_true_pred               NaN                    NaN             NaN   \n",
              "\n",
              "                    conf_drop_pred  entity_retention_rate  \\\n",
              "attack                                                      \n",
              "insert_true_oracle             NaN               0.432628   \n",
              "insert_true_pred               NaN               0.441705   \n",
              "\n",
              "                    conf_drop_gold_true_insertion  \n",
              "attack                                             \n",
              "insert_true_oracle                       0.102404  \n",
              "insert_true_pred                         0.065894  "
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1) Ensure columns exist\n",
        "for col in [\"entity_retention_rate\", \"conf_drop_gold_true_insertion\"]:\n",
        "    if col not in results_df.columns:\n",
        "        results_df[col] = np.nan\n",
        "\n",
        "# 2) Run insertion attacks\n",
        "true_insert_oracle = run_insertion_attack(\n",
        "    dataset_split=val_subset,\n",
        "    p=0.5,\n",
        "    span_source=\"oracle\",\n",
        "    baseline_preds=base_preds,\n",
        "    base_logits_list=base_logits,\n",
        ")\n",
        "\n",
        "true_insert_pred = run_insertion_attack(\n",
        "    dataset_split=val_subset,\n",
        "    p=0.5,\n",
        "    span_source=\"pred\",\n",
        "    baseline_preds=base_preds,\n",
        "    base_logits_list=base_logits,\n",
        ")\n",
        "\n",
        "# 3) Insert / update rows in the main table\n",
        "results_df.loc[\n",
        "    \"insert_true_oracle\",\n",
        "    [\n",
        "        \"precision\",\n",
        "        \"recall\",\n",
        "        \"f1\",\n",
        "        \"entity_retention_rate\",\n",
        "        \"conf_drop_gold_true_insertion\",\n",
        "    ],\n",
        "] = [\n",
        "    true_insert_oracle[\"precision\"],\n",
        "    true_insert_oracle[\"recall\"],\n",
        "    true_insert_oracle[\"f1\"],\n",
        "    true_insert_oracle[\"entity_retention_rate\"],\n",
        "    true_insert_oracle[\"conf_drop_gold_true_insertion\"],\n",
        "]\n",
        "\n",
        "results_df.loc[\n",
        "    \"insert_true_pred\",\n",
        "    [\n",
        "        \"precision\",\n",
        "        \"recall\",\n",
        "        \"f1\",\n",
        "        \"entity_retention_rate\",\n",
        "        \"conf_drop_gold_true_insertion\",\n",
        "    ],\n",
        "] = [\n",
        "    true_insert_pred[\"precision\"],\n",
        "    true_insert_pred[\"recall\"],\n",
        "    true_insert_pred[\"f1\"],\n",
        "    true_insert_pred[\"entity_retention_rate\"],\n",
        "    true_insert_pred[\"conf_drop_gold_true_insertion\"],\n",
        "]\n",
        "\n",
        "\n",
        "# 4) Show a compact view\n",
        "cols_to_show = [\n",
        "    \"precision\",\n",
        "    \"recall\",\n",
        "    \"f1\",\n",
        "    \"delta_f1\",\n",
        "    \"entity_flip_rate\",\n",
        "    \"span_miss_rate\",\n",
        "    \"span_token_error_rate\",\n",
        "    \"conf_drop_gold\",\n",
        "    \"conf_drop_pred\",\n",
        "    \"entity_retention_rate\",\n",
        "    \"conf_drop_gold_true_insertion\",\n",
        "]\n",
        "\n",
        "cols_to_show = [c for c in cols_to_show if c in results_df.columns]\n",
        "\n",
        "rows_wanted = [\"insert_oracle\", \"insert_pred\", \"insert_true_oracle\", \"insert_true_pred\"]\n",
        "rows_existing = [r for r in rows_wanted if r in results_df.index]\n",
        "\n",
        "results_df.loc[rows_existing, cols_to_show]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87712828",
      "metadata": {},
      "source": [
        "### Why do insertion-related metrics show NaN?\n",
        "Rows `insert_true_*` follow a *different evaluation protocol* (true insertion, no projection).\n",
        "Only metrics that are well-defined under length change are reported:\n",
        "PRF on the attacked sequence, entity retention rate, and gold-logit confidence drop at mapped positions.\n",
        "\n",
        "All other fields (flip rate, strict span match in original space, projected confidence drops, delta_f1) are left as NaN\n",
        "because they are **not directly comparable** under this protocol.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2040f73",
      "metadata": {},
      "source": [
        "## Key Findings\n",
        "- **Character typos** are the most harmful targeted attack: large F1 drops and high entity flip rates, consistent with Stage 2\n",
        "  (character noise brittleness) and Stage 3 (high attribution on anchor tokens).\n",
        "- **Context distractors** substantially hurt span integrity, matching the Stage 2 collapse under insertion-like noise.\n",
        "- **Synonym substitution** is mild, reinforcing Stage 2 results that meaning-preserving edits are tolerated.\n",
        "- **True insertion** reduces span recovery (entity retention ~0.43–0.44), showing that structural clutter breaks exact span extraction\n",
        "  even when overall F1 does not collapse completely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4d795e",
      "metadata": {},
      "source": [
        "## Plot overall F1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "id": "ff7f6e0c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGGCAYAAADmRxfNAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfVdJREFUeJzt3QmcltP///HTviChXdFCUSFKfYtkibLkG6JNmzWESrRRKIW0WCKVFtGCFiEpKaQIhUQlW1lKSUqpqPv/eH1+/3N/r5lmpsmdZrrP+/l4jJp77snM9biuc12fcz7n88kRi8ViTkREREREJAE5E/lmERERERERKLAQEREREZGEKbAQEREREZGEKbAQEREREZGEKbAQEREREZGEKbAQEREREZGEKbAQEREREZGEKbAQEREREZGEKbAQEREREZGEKbAQEZG9+u6771yOHDncI488ktU/Srag4yEisicFFiIiB7kxY8bYQ25aH926dYu/b9asWe7aa691VatWdbly5XJly5Z1B6svvvjC3XvvvfaAn9qTTz5px0RERA6s3Af4/yciIv+S+++/35UrVy7FawQR3vjx492kSZPcaaed5kqVKuUOZgQW9913nzv77LP3CJAILIoUKeLatm2bZT+fiEiIFFiIiCSJCy+80NWoUSPdr/fr18+NGDHC5cmTx11yySXu888/P6A/n4iIJDelQomIBIJVCoKKRA0ePNgde+yxrkCBAq5evXopApTRo0dbCtaSJUvSDGxIwfrxxx/T/be///57d/PNN7tKlSrZv3/UUUe5K6+8MkXKE2lOvIZzzjknnvY1b948W71YtmyZe/vtt+Ovs6qBjRs3ui5duriTTjrJHXrooa5QoUIWjH366ad7/Bzbt2+3VKuKFSu6/Pnzu5IlS7rLL7/cff311+n+7LFYzN1www0ub968bsqUKftwREVEkoNWLEREksTvv//uNmzYkOI1UoL2p2effdZt2bLF3XLLLfbw/eijj7pzzz3XLV261BUvXtw1adLEvvb888+7U089NcX38hoP+UcffXS6//6HH37oFixY4Jo1a+ZKly5tAcVTTz1l30f6U8GCBd1ZZ53lbrvtNvfYY4+5Hj16uBNPPNG+lz+HDBnibr31Vgscevbsaa/zc+Gbb75x06ZNs6CElLF169a5p59+2oIj/m2fHrZr1y5b0ZkzZ479HLfffrv9zrNnz7YgqkKFCnv83HzPNddcY6lmU6dOdRdffPF+Pe4iIgeFmIiIHNRGjx4dYzhP6yM9F198cezYY4/N9P/j22+/tX+vQIECsR9++CH++gcffGCvd+rUKf5a8+bNY6VKlYrt2rUr/trixYvtffysGdm2bdsery1cuNC+99lnn42/9uKLL9prc+fO3eP9VapUidWrV2+P17dv357iZ/K/V758+WL3339//LVRo0bZvz1o0KA9/o3du3enOB4DBgyI/fXXX7GmTZvasXnjjTcy/P1ERJKZUqFERJLE0KFDbVY9+rG/NW7cOMWKQ82aNV2tWrXcjBkz4q+1bt3a/fTTT27u3LkpVitIbbriiisy/Pd5j/fXX3+5X3/91R133HGucOHCbvHixQn97Pny5XM5c+aMrzDwb7OyQdpV9N+ePHmyrfSw8pEaqVVRO3futBWQV1991Y7BBRdckNDPKCJyMFMqlIhIkuAhP6PN2/vD8ccfv8dr7EN44YUX4p+ff/75tieBYOK8885zu3fvdhMmTHD//e9/3WGHHZbhv//nn3+6/v37214N9mKwbyGa6pUIfg5St6ga9e2331pw4bGXw2MfBcFG7tx7v0Xys/7xxx/u9ddfj+/lEBEJlVYsRERkv2KDdosWLWzmn30YrFywgnH11Vfv9XtZJXjggQfcVVddZcEKvTdYeeHBn8AgEWwe79y5s+3ReO6559wbb7xh/3aVKlX+8b/doEEDd8ghh7iHH37YflcRkZBpxUJERDLtq6++2uO1lStX7tFLgnSogQMHuldeecVm84sWLWoP4Xvz0ksvuTZt2tj3ejywb9q0KcOUpMx8jX+bKlLPPPNMitf5t6Ob3Nmc/cEHH1gq1t6qaP3nP/9x7du3t83epESxcTszKx0iIslIKxYiIpJpVFWKlotdtGiRPYRTtjXq5JNPto+RI0faygXVlTLzwM1qRzT9CY8//niKtCWwSoDUAYf/Wlqvp/Vvv/jii3uUv2UfCNW1nnjiiT3+jdTfj/r167uJEye6mTNnulatWiW8siIicrDStIqISCA+++wzN336dPv7qlWrbM9C37597fNTTjnFNWrUaK//BhupzzzzTHfTTTe5HTt2WHlX0pTuuuuuPd7LqgV9I5CZNCgw8z9u3Dh3+OGHu8qVK7uFCxe6N998M8UeCFSrVs0ChYceesh+DzZmU/a2WLFirnr16lailt+Nn5fX+Br/Nt3J27Vr5+rUqWMlctkHUr58+T1+bsrqkjZF4FS3bl23detW+znoscFekbQ2tbMvhO+lPwZlbEVEgpPVZalERGT/lJv98MMPM/W+tD7atGmT4fdGy6sOHDgwVqZMGSvTWrdu3dinn36a5vf8/PPPsVy5csUqVqyY6d/lt99+i7Vr1y5WpEiR2KGHHhpr0KBBbPny5VYaN/XPOGLEiFj58uXt/xEtPbt27Vorp3vYYYfZ6770LOVm77jjjljJkiWtNOwZZ5xhpWz5eurytJS97dmzZ6xcuXKxPHnyxEqUKBFr0qRJ7Ouvv97jeEQ9+eST9nqXLl0y/TuLiCSLHPwnq4MbERFJPqQTUR2qV69e7p577snqH0dERP5l2mMhIiL/ijFjxtjeCPYdiIhI8tMeCxER2a/eeust98UXX1jZWPYepK4YJSIiyUmpUCIisl/RKG7BggXujDPOsH4R0U7dIiKSvBRYiIiIiIhIwrTHQkREREREEqbAQkREREREEhbc5m06ov7000/usMMOczly5MjqH0dEREREJNti18SWLVtcqVKlXM6cGa9JBBdYEFSUKVMmq38MEREREZGDxpo1a1zp0qUzfE9wgQUrFf7gFCpUKKt/HBERERGRbGvz5s02Ke+foTMSXGDh058IKhRYiIiIiIjsXWa2EGjztoiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJCy4qlAicnDYMriqy04O6/R5Vv8IIvuFrq2M6fiI/HNasRARERERkYRpxUIki2hWTERERJKJVixERERERCRhCixEREREROTgDyyGDh3qypYt6/Lnz+9q1arlFi1alOH7hwwZ4ipVquQKFCjgypQp4zp16uS2b99+wH5eERERERHJZnssJk2a5Dp37uyGDRtmQQVBQ4MGDdyKFStcsWLF9nj/+PHjXbdu3dyoUaNcnTp13MqVK13btm1djhw53KBBg7LkdxARERERQej7J7N0xYJg4Prrr3ft2rVzlStXtgCjYMGCFjikZcGCBe6MM85wLVq0sFWOCy64wDVv3nyvqxwiIiIiIpKkKxY7d+50H3/8sevevXv8tZw5c7r69eu7hQsXpvk9rFI899xzFkjUrFnTffPNN27GjBmuVatWB/AnFxEREQlT6DPykk0Diw0bNrhdu3a54sWLp3idz5cvX57m97BSwfedeeaZLhaLub///tu1b9/e9ejRI93/z44dO+zD27x58378LUREREREJFts3t4X8+bNc/369XNPPvmkW7x4sZsyZYp77bXXXJ8+fdL9nv79+7vDDz88/sGGbxERERERSZIViyJFirhcuXK5devWpXidz0uUKJHm99xzzz2W9nTdddfZ5yeddJLbunWru+GGG1zPnj0tlSo1Uq3YIB5dsVBwISIiIiKSJCsWefPmddWrV3dz5syJv7Z79277vHbt2ml+z7Zt2/YIHghOQGpUWvLly+cKFSqU4kNERERERJKo3CwrCW3atHE1atSwzdiUm2UFgipRaN26tTv66KMtnQmNGjWySlKnnnqqladdtWqVrWLwug8wREREREQksMCiadOmbv369a5Xr15u7dq1rlq1am7mzJnxDd2rV69OsUJx9913W88K/vzxxx9d0aJFLah44IEHsvC3EBERERGRLA0s0KFDB/tIb7N2VO7cuV3v3r3tQ0REREREso+DqiqUiIiIiIhkTwosREREREQkYQosRERERETk4N9jIclry+CqLjs5rNPnWf0jiOw3ur5ERCS7UWAhIiJJR4GXiMiBp1QoERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmDZvJ0CbA0VERERE/o9WLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLERERERE5OAPLIYOHerKli3r8ufP72rVquUWLVqU4fs3bdrkbrnlFleyZEmXL18+V7FiRTdjxowD9vOKiIiIiMiecrssNGnSJNe5c2c3bNgwCyqGDBniGjRo4FasWOGKFSu2x/t37tzpzj//fPvaSy+95I4++mj3/fffu8KFC2fJzy8iIiIiItkgsBg0aJC7/vrrXbt27exzAozXXnvNjRo1ynXr1m2P9/P6xo0b3YIFC1yePHnsNVY7REREREQk0FQoVh8+/vhjV79+/f/9MDlz2ucLFy5M83umT5/uateubalQxYsXd1WrVnX9+vVzu3btSvf/s2PHDrd58+YUHyIiIiIikiSBxYYNGywgIECI4vO1a9em+T3ffPONpUDxfeyruOeee9zAgQNd37590/3/9O/f3x1++OHxjzJlyuz330VEREREJHRZvnl7X+zevdv2VwwfPtxVr17dNW3a1PXs2dNSqNLTvXt39/vvv8c/1qxZc0B/ZhERERGREGTZHosiRYq4XLlyuXXr1qV4nc9LlCiR5vdQCYq9FXyfd+KJJ9oKB6lVefPm3eN7qBzFh4iIiIiIJOGKBUEAqw5z5sxJsSLB5+yjSMsZZ5zhVq1aZe/zVq5caQFHWkGFiIiIiIgEkApFqdkRI0a4sWPHui+//NLddNNNbuvWrfEqUa1bt7ZUJo+vUxXq9ttvt4CCClJs3mYzt4iIiIiIBFpulj0S69evd7169bJ0pmrVqrmZM2fGN3SvXr3aKkV5bLx+4403XKdOndzJJ59sfSwIMrp27ZqFv4WIiIiIiGRpYIEOHTrYR1rmzZu3x2ukSb3//vsH4CcTEREREZGkrAolIiIiIiLZkwILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERFJmAILERERERHJXoHFmjVr3DXXXLM//0kREREREQktsNi4caMbO3bs/vwnRURERETkIJB7X948ffr0DL/+zTffJPrziIiIiIhIsgcWjRs3djly5HCxWCzd9/B1EREREREJyz6lQpUsWdJNmTLF7d69O82PxYsX/3s/qYiIiIiIJEdgUb16dffxxx+n+/W9rWaIiIiIiEhy2qdUqDvvvNNt3bo13a8fd9xxbu7cufvj5xIRERERkWQNLI4++mhXrly5dL9+yCGHuHr16u2Pn0tERERERJI1Fer4449369evj3/etGlTt27dun/j5xIRERERkWQNLFLvn5gxY0aGqVGZNXToUFe2bFmXP39+V6tWLbdo0aJMfd/EiRNtXwfVqkREREREJEka5P0TkyZNcp07d3a9e/e2qlKnnHKKa9Cggfvll18y/L7vvvvOdenSxdWtW/eA/awiIiIiIrIfAgtWB1L3qUi0b8WgQYPc9ddf79q1a+cqV67shg0b5goWLOhGjRqV7vfs2rXLtWzZ0t13332ufPnyCf3/RURERETkAG/eJhWqbdu2Ll++fPb59u3bXfv27W3TdhS9LjJj586dVr62e/fu8ddy5szp6tev7xYuXJju991///2uWLFi7tprr3Xvvvtuhv+PHTt22Ie3efPmTP1sIiIiIiLyLwUWbdq0SfH51Vdf7RKxYcMGW30oXrx4itf5fPny5Wl+z/z5890zzzzjPvnkk0z9P/r3728rGyIiIiIikk0Ci9GjR7ustGXLFteqVSs3YsQIV6RIkUx9D6sh7OGIrliUKVPmX/wpRURERETCs0+Bxf5GcJArV649StbyeYkSJfZ4/9dff22bths1ahR/bffu3fZn7ty53YoVK1yFChVSfA9pWz51S0REREREkrAqVN68eV316tXdnDlzUgQKfF67du093n/CCSe4pUuXWhqU/7j00kvdOeecY3/XSoSIiIiISIArFiBNib0bNWrUcDVr1nRDhgyx3hhUiULr1q2t4zd7JehzUbVq1RTfX7hwYfsz9esiIiIiIhJQYEH3brp59+rVy61du9ZVq1bNzZw5M76he/Xq1VYpSkREREREsq8sDyzQoUMH+0jLvHnzMvzeMWPG/Es/lYiIiIiIZJaWAkREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJGEKLEREREREJDkCi6FDh7qyZcu6/Pnzu1q1arlFixal+94RI0a4unXruiOOOMI+6tevn+H7RUREREQkgMBi0qRJrnPnzq53795u8eLF7pRTTnENGjRwv/zyS5rvnzdvnmvevLmbO3euW7hwoStTpoy74IIL3I8//njAf3YREREREckmgcWgQYPc9ddf79q1a+cqV67shg0b5goWLOhGjRqV5vuff/55d/PNN7tq1aq5E044wY0cOdLt3r3bzZkz54D/7CIiIiIikg0Ci507d7qPP/7Y0pm8nDlz2uesRmTGtm3b3F9//eWOPPLIf/EnFRERERGRjOR2WWjDhg1u165drnjx4ile5/Ply5dn6t/o2rWrK1WqVIrgJGrHjh324W3evDnBn1pERERERLJdKlQiHnzwQTdx4kQ3depU2/idlv79+7vDDz88/sGeDBERERERSaLAokiRIi5Xrlxu3bp1KV7n8xIlSmT4vY888ogFFrNmzXInn3xyuu/r3r27+/333+Mfa9as2W8/v4iIiIiIZIPAIm/evK569eopNl77jdi1a9dO9/sefvhh16dPHzdz5kxXo0aNDP8f+fLlc4UKFUrxISIiIiIiSbTHApSabdOmjQUINWvWdEOGDHFbt261KlFo3bq1O/rooy2lCQ899JDr1auXGz9+vPW+WLt2rb1+6KGH2oeIiIiIiAQYWDRt2tStX7/eggWCBMrIshLhN3SvXr3aKkV5Tz31lFWTatKkSYp/hz4Y99577wH/+UVEREREJBsEFujQoYN9pNcQL+q77747QD+ViIiIiIgEURVKRERERESyBwUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSMAUWIiIiIiKSHIHF0KFDXdmyZV3+/PldrVq13KJFizJ8/4svvuhOOOEEe/9JJ53kZsyYccB+VhERERERyYaBxaRJk1znzp1d79693eLFi90pp5ziGjRo4H755Zc0379gwQLXvHlzd+2117olS5a4xo0b28fnn39+wH92ERERERHJJoHFoEGD3PXXX+/atWvnKleu7IYNG+YKFizoRo0aleb7H330UdewYUN35513uhNPPNH16dPHnXbaae6JJ5444D+7iIiIiIhkg8Bi586d7uOPP3b169ePv5YzZ077fOHChWl+D69H3w9WONJ7v4iIiIiI/Ptyuyy0YcMGt2vXLle8ePEUr/P58uXL0/yetWvXpvl+Xk/Ljh077MP7/fff7c/Nmzcn/PNv2b7LZSex/fA77U86PhnT8cmYjk/GdHwypuOTPh2bjOn4ZEzHJ7zjs/n//xuxWCx7BxYHQv/+/d199923x+tlypRxSafH4Vn9E2RvOj4Z0/HJmI5PxnR8Mqbjkz4dm4zp+GRMx+eAHZ8tW7a4ww8/PPsGFkWKFHG5cuVy69atS/E6n5coUSLN7+H1fXl/9+7dbXO4t3v3brdx40Z31FFHuRw5crisRhRIkLNmzRpXqFChrP5xsh0dn4zp+GRMxydjOj4Z0/FJn45NxnR8Mqbjc3AdH1YqCCpKlSq11/dmaWCRN29eV716dTdnzhyr7OQf/Pm8Q4cOaX5P7dq17esdO3aMvzZ79mx7PS358uWzj6jChQu77IYTJzucPNmVjk/GdHwypuOTMR2fjOn4pE/HJmM6PhnT8Tl4js/eViqyTSoUqwlt2rRxNWrUcDVr1nRDhgxxW7dutSpRaN26tTv66KMtpQm33367q1evnhs4cKC7+OKL3cSJE91HH33khg8fnsW/iYiIiIhIuLI8sGjatKlbv36969Wrl23Arlatmps5c2Z8g/bq1autUpRXp04dN378eHf33Xe7Hj16uOOPP95NmzbNVa1aNQt/CxERERGRsGV5YAHSntJLfZo3b94er1155ZX2kQxI06I5YOp0Lfk/Oj4Z0/HJmI5PxnR8Mqbjkz4dm4zp+GRMxyd5j0+OWGZqR4mIiIiIiGTnztsiIiIiInLwU2AhIiIiIiIJU2AhIiIiIiIJU2AhIiIiIiIJU2AhIiLBUL0SEckKsUDGHgUWB8iuXbtc6CZPnuxee+0198cff2T1jyIHud27d2f1j3BQCf14ffvtt65Lly7ur7/+cjly5MjqH0cOMvPnz3cDBgxwP/zwQ1b/KHIQWrNmTYqxJ9kDDAUW/9INfPv27e7HH39077zzjp1EuXLlcqEfl8cee8w1atTI3XXXXe6TTz6xYySZk+wDUWYsX77c9e3b1/3999/xppmhPzBH+WPBn4w9S5Ysce+++66dO9EmoyH68ssv3eOPP+7Kly/vxowZE39d19Wek188AP3888/uvffeszF6586dLnTjxo1zI0eOtMa8L7zwgibHJNO+/vprd/nll7unn37arVq1yl5L9skN9bHYj7ihcwPnz/bt27u5c+e6I4880m7wr7zyimvQoIELHasWt912m11YBBiXXHKJK1u2bPAPPtHzB7/99pvbsmWLHaeiRYu6/Pnzu9A98cQT7uGHH3YVKlRwN910k7vqqqvsdT+EJftgndnz57777nMzZ850P/30kytcuLA7/vjj7WH60EMPdSEfm++++87OoeHDh7tatWrZDPRpp50WP4dCP3887l2LFi1ya9eudX/++acds+bNm9u5FfJxeu6559zo0aPtXKpWrZqNP7Vr187qHytbCvk8SX0cNmzY4K6//nqbTK1evbqdN/Xq1XMlSpRwSYvAQvaPXbt22Z/t27ePnXnmmbH58+fH5syZE8uRI0fsjTfesK/9+uuvsRD99ddfsd27d9vfV69eHStXrpwdlxo1asQmTpwY27BhQ1b/iNlGr169YmeddVasUKFCserVq8f69u0b2759eyx069evj02ePDnWsmXL2CmnnBJr0aJF7LPPPtvj+gvR33//bX8y5hx22GE23qxduzZ2zDHHxO6888748Qt1/PFjz6effhrr0aOHjT18cC5xnFK/L9Tzp3///rHKlSvHZs+eHfvtt9/sGD3//PP2tZ07d8ZCPjbgfl6zZs1Yvnz5YieddFLsgQceiH3xxRex0Pmx948//ohNnz491qlTp9htt91mxybkcTnq3XfftefCE044IXbTTTfF5s2bZ8crGcceBRb72c8//xwrVqxY7J133rHPL7/88ljTpk3t79zUueAWLlwYCzGwwLhx42JnnHFGrEuXLrERI0bELr74Yrt5XXbZZbG333479vvvv8dCvnkxKBctWjQ2adKk2E8//RTLlStXbMCAAfa1zZs3K8CIxeyhmQdCzhsenO+4447YunXr4l8P+UbWuHFjG2Mwbdq0WPHixeMPzs8++2zsmWeeCe4c8ufDjh07YhUrVrTA4rHHHosNHDgwVqVKlVjBggVjDz/8cNDnDTgvypcvHxs/frx9fvvtt9uDELZu3Rq74YYbYnPnzo2FOjbzYFi7du1Yhw4d7DriWuP8adCgQWzs2LF27w+Vfyi+9tprY9WqVYtdd911NjaXKlUqxdgcoj///NP+/Pjjj2Pdu3ePHXXUUbH8+fPb5Op9991nk2PJNvYosNjPMxqrVq2K1apVK7Zp0yYLIAoXLhxbsWKFfY0bPIPQiy++GAtVhQoVYo8++miK12bOnBkrWbJkrGzZsrEbb7wx2OACderUifXr1y8ehB177LF2LuHJJ5+0GbMQ+YGXWXdu7jfffHOsd+/esdatW8dOP/10u5lxsw/12HBj58G5VatWtuKFMmXKpLjWOnfuHGvTpk0sVExmsAIYHbe//vrrWNu2bS1I5YbPik+IOH82btwYO++882LLli2L/fLLL7FDDz00PkFG0NGoUaPYI488EgsVE2JMYkRNnTo1dvTRR9u9i0lEf68PcWxmYpBzhmcg1K1b14JTrFy5MsiVnd3/P+BiZYJVrlGjRtk5smXLFpsAYlKD58Xhw4fbMUoWSmzfD9iY7TdOFitWzP7OBi9yVW+++WZXsWJF+9q8efPc0qVLbQNziMjZLViwoDvkkEPimwTZiMvek7Zt28artxQqVMiF5P8H+Lan4vDDD7c9BOjUqZPly/MaGys/+OADN2PGDBciv/fkjjvucIcddpgVArj33nvdk08+6Xr27Oly585t1xo58+xpCgG5u9FjkzdvXts78P3339uxKV68uB0T/94JEya4//73v8Fueuf4HH300fHPOW5s5ma/zkknneQuuugiV7p0aRdipULy4RmbGYNGjBjhWrZs6Zo0aeLq1q1rX//oo4+sMlLTpk3t89C2Zm7atMmumXz58tnn3LfQuHFj9+CDD9qxZB+cv9eHxI8/06dPt/OD+xd7Ub755hvb7A727Nx///227yskOf7/PhOuKcaadu3a2TnCfrdBgwa5OXPmWGGJjh072r64ZKHAIgFvvPGGbcb57LPP4hcXDz033HCD69Onj1UDOP/889369ettI3f37t1d586dbXAKsfwsm5W4sY8fP94+z5Mnjz0QwgcXr776aoqBO5lt3rw5PvjwwblDYEoA0atXL1e1alXXunVrew9VWggqfFAa4oMhFWrYTMpmZF9ljSCVh2UCsGOOOcY2VTKAJzuujzZt2rgePXpYKUN/A6tfv75NYHATb9iwoVX04eZFkMrxueyyy+x9IRZLOPnkk62IxvPPP2/Xjz9mp5xyio1LBBjHHntsENcWG0nZQMpY43FfIlDnIXDhwoWuTp069vpbb71l5w/BBoEX967QNuZSBOHss8+2a2njxo3x+5Y/ry644AL30EMP2ech3duj1wrjy1dffWV/Z2KDCZ8iRYrY50x2/Prrr65UqVIuRJUqVXLbtm2LV4Xi7xw7JjQYs7t16+aaNWuWPEF7Vi+ZHOy53iyPHnHEEbHrr78+RQoPS15HHnmk5fSyVHriiSfae0IV3TzJsjGbttmIC5YGWWa/9NJLY6HgXLn66qtjL730UoqN64sXL7bjQ2rGkCFD7LVFixbFrrzyylj9+vWTbpPXviIvnvSwDz74IL5vB2vWrLHzh9eRbDmrqX377bd2/rDJv2HDhraUvm3bNvsay+xsDuQcIo+3SJEidv74pfZo6mZobrnlFkudu+eee2IfffSRXXvsryANKno+Jbvly5fHTj311FiBAgWs2Mh3331nr3MM2KxNGkvVqlXt3nb88cdboQQvtPHHXy9LliyJlS5d2u7pM2bMsOuMexfHj3MqJJ988skerzG+nH/++ZZOx7kTHau4vqZMmRLs+LNq1ap4uhwpq1Fnn3127NVXX02qa0vlZhPAoaOE4euvv+6eeuop98svv7g777zTGjFh69at7tlnn7WUBJYHTzzxRFuOZ0YjhL4W0fKpYOWG0qksq5PKwooPWBZkBoia+z6VLNlnVJctW2azx/yeF154odW5PvXUU+1YvP3223Z8mB074ogj7DyrXLmy1VFnxieU8yet8oUsr7dq1cr+TloUqU+s9DzzzDM220oqXShYtXj55ZethDOro+XKlbNZZb+qtXr1alu9qFKlis2YcW6FWAaS33nHjh12vPjd+/XrZ/2FSMtgtYcVMGbkr7vuOntPdDY62b344ouua9eutnrKivott9xiKT3MMLNywbFgFYfV05DuXamvE9J2WWHnHkaZ9LFjx9o9nZlnVk05jqx8hXB8uEZYFeY+TW+Giy++OP46K6Wk/XC/opQ8KWSk0LEaFloabyzVOcTqIFkZnEO33367rf69+eab9vzIak4yjcsKLPYDLqgVK1ZYnWsCCZZNuXn5fOYQb+ZRDMIMKuR5E1hQF50UDR58WJLnYZkUFpZSQxiYozgWjz76qO0rIT/10ksvdSeccII98HBOsSeH5dLTTz/d9lqEEHTtDQE8+5cIwAjWaZzHNUfzPJaTQziHog/AXFfs6aKrPWkanCvXXHONXVOh8ucAaTykXrLvhlRM0sNuvfVW9+GHH1qwwbHjONFLJyTRexJjMWk89IhhDOY68ilzofLHh3s6D380C6xRo4adO+xjogElewqOO+44e8gmbz6UsZlj8+mnn7qhQ4faXopzzz3XJsK4b2HatGl2TyMY4ziR/k3vBiZYQxibY5Fri3sVAQUThGeeeabtpyAIpa8Q72EykQkNxqWkmtTI6iWTg5VfzqPW91dffWWfszRK1R5KYR5++OGxiy66yJacQ+TTCkgJq1SpktW0Hj16tKVnjBw5Mha6aE14qrFQwpCUOdKdKAtKVZbQ+WuMa4qKRlT0oRoUVcRAHXAqZXG8SGsJEekZvnzs559/HuvZs6elR9WrV8+qi/3444+x0Pg0OKqpUfq7a9eudo6Q0kOJ0ND548N5QwlM7/vvv7d7V86cOS01Na10l5DGnTfffNMqq3HvIlWFe1fqioYhI/WSfieUJKYsOumXlCX25xj3MJ+eGeL5M3LkSOt5Qs8lzp1zzjnH7vXR6y1ZKbBIED0qaEAVLaVGPesJEybYicQJ9frrr8dCRR3rp59+2v7ep08fezgkx5AH68GDB1v+ZWiieZQEpR71rNknQIBB/vwrr7wSbONA//BDM0VKEVNDn5s611Pqko9RyZKjmpmgfdiwYbH//Oc/sVmzZqX4OoEYARj7uvgzNP4cYE8b5b39mHzIIYfE9+DwoMhHSPsqUl9bPDATSNCfIYqSu+wd5FrjPhYqSljfe++98bKyBBmUuwYTGtHGiiE+OEdLqVLqm/1clNenR0yo/DHZsGGDNSplMpXnHfa48TyIaFO8ZKXAIoELi0GXZmZsSE7rgYaHZm7+oeK40HOAC4mVHTpJ87AMBuXmzZtbI7hQz59BgwbZgyGBZ/T84SZGbWs23Q4dOjQWMja78fCDH374weqkMzMPjltodeP9ecLNipv4mDFj4jeq6EMys9Hc1Hxn8mTfzJ5WU6qrrrrKJi/AKg7Nu/xxomMyG7lTb6RMdv48WLBggdXQpzCEP29SnyOcP9EZ1pAwm0xwxT0MJUqUiE+QkZnAytdDDz0UC9kTTzxhm9g5fxiXOGY0n2SMPvnkk+1roerWrVu82AorfwQZfnWQ/lT096BhcrJK/oTAf4HPESTHkA2klJuL7qEgYGPvACUMKT2LEEoYpkb+KZvb2ZTdoUMHK9fHhi788MMPliPv88BD2erDecD5w2YtSsqy0b927dp2/pDr7Gujv//++9aDgLzMkI5PFMeIHHi/V4lNglxPbEam7Cw5zuRAh3Rs/DjDRnU2j1KOuECBAvaaz89lIzf7B9goyP4chJD77XE+sAGZ/TdsQp49e7b74osvrAQmuP44d9g8yYbkkM4ffx4MGTLEyhWzH8ffz/zX2H9CaWfOH188IjTsNfntt9/cxx9/bHtO+JweBPj999/t/l6zZk37PKTj40vpDhgwwA0fPtyuH8YdxiWOEdcYm7XZN0m52VAVK1Ys3jPntttus6IaFBrx5wt7JxmjklU4d5v9iBODgZdqEDQU8hecH2B4jWZUVPXxDwKh3Nj9MWAzKRUh2LjFRnZu5FTTAA+L1G2mjrrf9BbK5nZ/HrBZkhvTFVdcYVWNwCANKh+B3gwErQjl+EQdddRRtuGW64lNuGxM9ucQD0PU2udmxrEJ6eYOHvj8DZ1zKlo7n0ZLVGdh82RIfO8bNtryQEjAzuZSeuT4KiyMSWwsJfhiDAoN1wnHiWCUqoXRscV/bcqUKRawe6GMPX7yj9+dSY177rnHKhwxDvNwSFUo7l28XqZMGZsoC+n4cH4w7jKpwz2dibHzzjvPvubHH44R1bHoR8Wm91B6UkXt3LnTqqgtXrzYGgSyYZtAzB8LGuOdddZZ1pAyWSecw3ja3c8YSIg2qUTjLx4uuGglAAYkotaQ+GoINAOkkyQXDVV6GIT/+OMPqxzBbDylVRmghw0b5kJF6U/OH/Bg6LtvM/AwG83NLLSH5ehNiHMIlOIlOPVNhKgsQqDB4MzNn4oaId3cPQIuyoFSXcSvgnlUHeGc4iYf0jnkV2w4Vz7//HMLKKZOnWozhQMHDrTVnTPOOMMeHKnGBl+CNhT8rhwnKvgQfEU7IfM1ZuPHjRtn5xdCOX/4PblmmNS58cYbrSIf1Y5YMWblfdSoUbZyygcrOnweWjM8f51QHpXS1j6wgh9/eJhm/OHh+sgjj7TXkqbSUQb8eUDzzTvvvNP95z//sQ/GGc4hzisq05HhwgRZ79697f1JO/ZkdS7WwWzZsmXW9OS0006zRmd+4yTVoHyztxA2k6bGJu3UG2w5PuSltmnTxhq/ff3118E2y/EVI2igyMbJ1BtIqSQxYMCAYM8f8t7ZOEolH79Rko2UVPUhN5WGQmxM9jm8IW7Axa233mpNzu6+++7Y+++/H/vyyy9jXbp0sfPKVx0L5fzx4wib/dlbQUWo6F439jNRaINKWTShDJU/Hyg2QrM3Kva99tprtin57bffjrVu3dqal4aKKoZ+L443fvx4G3fYE0gzRV/pMbR9S9FKdFRb84UQfFU6TJs2zZrkbd68ORaiKlWq2EZ2UBWrU6dOsfLly8cqV65slbPYxM0zYrLft9THIkGkaNC4bNasWfY5S8wsgzErRipHSLWtib45Diylk+PNrE7SRuQJHif2mNC3gpkO0ntYPuZc4ZgxC/3zzz+neH8I/LXCrBcrEhwHZrtYoWAFg7067D2hjjx19pl9DhmzYKT1MBPG39euXevOOeccd9NNN9mqYFLVRc8EVkGZbeZY0LiLVMOMrp+Qrq20MMawGjhp0iTr48FqBcds8ODBtqIRQs+B6HnAPpz+/fvbjDI9YaJCORaZwSoXKVDs8XrppZfiewVIvaxbt67N1LOHJ5RnH39usEr64IMP2v3cpzCD+xkNKGkSyJ6mEMZkBRb7iMZl7J3goqIjKTne5O2ySZBuyjTLoeskDc9CubCiSDcgqGK/AM0CSWXxewgQ+s08ijxvGr2xEZDziKZDLJuylMpG5dAeDP1Ni3x4miey6ZbrKCMhnE/+xkVXcW5epLCwGZCO0eD84T3kzNPEi9zdEJGiwnFZtWqVbfLn4YaHHp9i6FPDkv18Sc3/zhTSWLBggTXa5MMXhqCJGRNkbHbn/kUKS4jHiXx4Uph5CCTtknOoZMmS9jWfCx/a/Tyja6158+a2wZ17GPtN2dtECtlXX30V3/cWyjlEN23u2StXrrRzJ8T9W1EKLDLBP+CRO0iFCGZ2mNVg5pTNt40aNYpXABBnDz7kvrNpiWpQ1157rT0EhfaQ7PkAk1UKHnp4aObcqVSpkn2d2Xhmm9lzQT44+whCNXHiRNenTx+bdWZw9rmofkaMh8OQAnb/u/Kwc/7559ufRYoUsZs43bXJ2eWBUP7vWHGNMYvK5lL2MbHyxeoNQnrQSX3volIPqxNcV4w7rCiTI09lKF85TJxNZlDtkXGamXf2VFxwwQU22xw6f/1w7nA8CCIo0sKeHCaA2JDMnkpWvUKaFOO4cG+iwiPZGnnz5rVrjQqYrAQGKatzsbK7aI4yjbr69+8fr1OcL18+683QsGHD2AsvvGB19kOTOoc7mndKbjwdyI899lhrmhPi8fG53z/99JM1yClevLjloJKj2rFjx2BzUdNDTwb6U1x33XWWA37uueemqIceyp6B1NdTixYtYhdffLGdLytXrrR8Xa4r6qOzHyfEaysjNJ685ppr7Didd955Qe+rwAknnGD53mCfCb0G2J9Dvxz2vNFAMDTpjSXkvtM/iI7S9LK46667rGlgiPz966233rK+L5wvPPswJtMrxmM/gcRs/80VV1xhTW7Zk/Pyyy/HmyqGRIFFJj3yyCO2qdY3dzvqqKNi77zzTuyNN96wRkM8KNIwJlQLFy60YzRw4MA9mrpxQ2Mz7uOPPx4L9eZ14YUXxpo0aWINp2gKSFDKgyHBKhsGJSUaKk6cONEG6YoVK9qmf9/sLTSrVq2yc8U3WOJBma7SBGEEXlxbbBCM3uhD4Dc/cjNnEuOmm26y8efNN9+Mv4cNyYzbnEOhYrxh86gfiziXaNw6c+ZMa/DKZEeIHdqjzQI5HnQip3mZR8M3HqI5XgRjoR4fukjTIJAxmE7kPOuccsopNjEWasAVxXVFYBUNIKZNm2bjDsURKAbAxGJIFFhk8gJ79NFHrbIIqBBB1SeieW7mzEATzfMAENKsqp/NmD59euyYY46xj7p169rFROdNLi5vzZo18feHcny8jz76yG5O3KhAt20q+jAolytXzh4MTz/99CArZPnfmVl4Vv2YHaQ7ux+IqR7GtUelGgKzUIP2Dh06xLZu3WqTGQQRfqxhTOLhZ+7cuUFVqvFjCL8v40716tXtHGHcoct2z54947OodLj1KzrJXIklPc8991w8cKBbNLPO27Zts8+vvvpqe2CkolhI548fd1jJKlWqlF1T3MeZJCQIjQandCdnoiO0e5f/XTlHqOjog4wCBQrYaiDZCLVr14517do1uBVTP46wctOoUaPYSSedZKuCN9xwQ/zaAhkuDRo0iIVGgUUmLixKF3LhLF261AYkLrLu3bvH33f55ZfbUmH0e0LC7MV9991nJS4ZgGfNmmWDEQ/LtLP3Qjw2vtRus2bN7O+TJ0+OHXfccfHZjTvvvNNmWv3MTyg39ujvSnpPhQoV7IOysnnz5rU0BJaR/ft4oPaBWQgBmL9xffPNN/HglOPw/PPPW/DODR7MtLKqE+o1Rqld0lX89cTqBWMz5xIBaaj8tUVKGGMyf6J9+/axG2+8Mf4+Vr6eeuqpWKh46GNScMuWLVY2ldLEBFqMQRMmTIiFjglBxmQfaFHq2weppNARXDAehZTS68dYyqIfcsghdj0RQJCxQXBx1FFHxV588cU9xvIQ7lueAou9DMzMxletWtUGHn9CsWLBrNjs2bPthGKW4/fff4+FxF8kzHQRWKVOU+FGxsoFEXyI/PHxD8PMevkZQ+rpe/fff7+tXoSM2S9mC7mJ+XOHWSDSxUK/uXPjjt6kGHNY4SKgIFXsiCOOiNdNDyUo9dcWExk8FPOAkxqpK+x/89dfSPx5wNhMjyVWt/xrrHAxsTF69GhLwcyTJ0+8L0MoQak/fwjaCbTo4xHFjDP3NPqhhI7U3TFjxtg5xD2elLrPP//cvsYqKZNi9LUIafzx1wlpc+yvjQYQHKfrrrvOArCQ950osNgLZnR8szd/QpGTyeDMTZ2gg/zeEJfZSc3473//axuVBg8evMfXeY0Ny6EFXdEZDVIzaILn8RCYM2dOe2CeN2+ebaIk9SekgTl6c+cmzsOhDyCiszrMJJLeEm3AFNL5QxBRv359O4+iCEaZUWUMSt3MKyQ8+JGWQToG6U5RBKekGbLHIlTkwLPpPzq28HDImE2zSVZ1yJkPbTbVY2WCvQOkzXn+ONGck9nnEANT/xxDFgaNN9lT6tPGGHOYbPX3MgLXkPjzg4CLFLDoJKEft997771Y4cKFU6SChyaMemD/sMQjtZopF0aNZv869eRr165ttZrnzZtnjYRKlChhXw+pgQ5B6bZt2+yYUH73ySeftPrn9evXd6VKlbJyc5TEpI783noRJBtf0pKa6EWLFo3Xi0eTJk3svKIML80Ur7zySitLh1BKqEavlRYtWlhfGEo2U6qQ17dv327nzUUXXeReeeUVK/1YpUoVF1JJxz/++MOOCz1gKLEbLbd7zz33uE6dOrl169a50qVLB9vAi545v/76q/VguPfee60xFWW/OX70hKG2PH09QuLPA/oqHXfccdakNTq2UFp29OjR1gyOXky+tHVIYw9++eUX6/dCnwoaAnLMaCzJvZx719KlS62kKv2FQuPLxFLemnOF0ugoU6aMHS/uazQFpmEpDTpDGn/8dTJw4EA7Bjt37rQ2BNzX/X2/Tp06Ng75JrchUh+LdHBYeCBcuHChPSz7zto8SHMy+W6T4iyA6Nmzp93MqlWrZoMPgzN9LKhz7T8Poa61D0rpFk2wxcPNI488kuJrNKTixka963LlytkNLpSBOYrA9IknnrDgYdGiRe6BBx6wWuAeDRa7du0a5ADNuUMXV/pWjB071urpeyGeK+lhLH7mmWdcr1697EGQhpz0GOJaozswAbwPyEJSr149e/CjZ8WMGTNsnAm1l0dG3nnnHevDQCDKOcNDNGM2kxs0zKMnQ0jXW7TnEn2EnnrqqRQNbt9//303YMAAa7B46qmnultvvdWFiPv3mDFj7B7Fcw29ci677DLrMTR58mQ7d7hvMXkY5DWX1Usm2Xk5kBxCKq6whyJ1Sgv5vaHkpKYn9fL5008/HTvxxBMtB/yyyy6Lvfrqq7GQU+iooU+aGEujkjZSoSij2rlzZ9tPwFJ73759Y61atbJzaMSIEUGmGX733XdWOpU0H9JWunTpEs+FDy1tLjPIZ2bvG6lRjD/R3ichIjWM/X8cD/pVkFYX+v0qKnr9ULaZ1KdLLrnE9uWQfsm+Ai+040ZFPja1V6lSxVKh0hp/o8cvtLEoej6w34Q9FRwrNm1Toa5ly5ZWbAShpfF6Ciz2gv0B9KpgMynNqGh68uOPP2b1j5VtAwwG6XvuuSdWpkwZq7fPJkFfGjMkbEQmx/nII4+M1atXLzZ+/PgUTahCu1ll5jrj4YcKR9zc2b/kS6j6QD5EVFWjchiVj+hZQaWj1PsJ5H+o3HfRRRfFcufObYUjVqxYEQsZwSgPzOzrYr+FLysrez4Uc1+nsg+NKKlK16NHj9iyZctioWGih4lUzhn2oVC4JvRxOLXUwRTPiGz4Z1/XrbfeapOqqffGhUSBRRo4Iagdz8YtX0/fV0eoU6eOzYhxIkn6AQYDMg+J+fPnt1WfULHKxQMhfSx40KFsX2ib2fcFN3fq7nPM2ADHzT2E1Qp/7VC2kYdhShRHGy5xo2KjNlVZQmxmtq+mTp1qm5PZ5B5CIOYnKiioQTD6xRdfxKv3gMpHlA3l3hWtMiZ7TvJ88MEHFsyzMTm6OTek48E4TKNbGrjyEW0cqEmxtAMMxnCaJNetW9cCUypmRVeZQ6LA4v/zDy8sYV1wwQU2a8oyMuXEuMAILDhxGLRJUQjhYeefXmjRWQ0qaEVvcMk+wHBjZ7WC35tzxqOCBv0+SI0iZUxSit6suM6YWX344YctICtdunSKpkPJeu5wDKjYw2ofN3NmDNu1axdvPkU/Am5c9LSIfp+k5I/LunXr7CExpNLfrKwTTHHd0PmXVVNfxpl71mOPPZZi5VT+J/X1NHbs2HgqUKhIyaQ6H+cUq6ZK6937ufPTTz9ZYErTvNA6bnvavJ0KVSCo0tOqVSvbxPTYY49ZFR92/ffr18/e4zdz+Y1OkpI/PlSuYTMc1X6SmT8Ptm7dapVFZs6cadVY2OB1/fXX2yZcsIm0R48ermnTplatJshNXfvo1VdftQ1wbMRN9vPn5ptvdkuWLLEKR6eccopbsGCBu/POO20jKceBzZKh29s144tEcBzZfDpp0iRXuHBhFwI2GpcvX9517NjRzhmqFlJZ7Nhjj3XDhw+3IhGexp60+Y3+bMzl74zfodyvqXTJ+UIhjeOPP94KsTRs2NDOEzZtU0hjw4YNbtmyZVn9I2dLXFOMP3ny5HE//fSTjeu+al9wsjqyyU5oOMXm0dRLfaRAMXs4adKkLPvZspv0Zkv97BmzZMxyhLCJ0h8LcpjZT0EaCzXABwwYECtVqpRtBly5cmVW/5jZxt5m2v2KFzPzpEL9+eefsWRHug4rFb6nSTQtk14WbGYP+VzZ13xlrrnbbrstFor58+fbaiirNB6rfNzTWH3XKunexx7/NcYfUnh948lQrq+KFSvG/vOf/9jKBGlzpPTcdddd8XNq06ZN8b+HmLGxtxQw/+wzd+5ce/YJeS+uptsjKCFLlEndfPz555/2Z5s2bdy5554bfz0kqRe0/DFhhpWZjtRf9ys47du3t1Ueyj8mO35nSu2+8cYb7qGHHnJXXHGFO+ecc9xtt91mNa45pyipGirOEzAjhr2t8vnSoJw/zKSFUNqZ0sP0f4mW1qWUKq9zDTFLSN+KkBaY+V39uUJZYlYCd+zYET8GXFfR48FsIZ577jk7jvT7CAXHApT49p+z0sfqaOPGjW0Fx78nFKl/X1Yg/Pnkz5Uofy4xbtOrql27di7Z+VUrVrno4cHK6Pz5892UKVPsmYdy8c8//7y9hxKzxYoVs7+HUDo+tb2t8PmSxF27dnW33HKLjeehUmARQbM7HpypQwwG5ujDToj19P3FREoB6WEtW7Z0bdu2dWvWrLELia/7AZkHSD6nYRVpHH369HGh4EZFMzz6Dng8FNIsh3Qwgg6anoXID7g33nhjvKFSeg85/ob/+OOP2zVHKlAISFMhZYVeHvTO8ecPeJ0mlEcccURQ6Sv+HGEcodcADzb0quAY+IdEP/7w4R92SIHq3r271ZQPBWkr9KqYNm2a++2331IE7/7eFVrarr9WCEoJEpiooD8M/LniJz18OtDKlSstMOU6DOFa43ckhZeJCybESOHlWuJcIiWTCUJSwNeuXetCEp2w+Oabb+y8eemll6y/BxM+6d23Ro0aFdykRpqyeskku6FuPsugZ599tm3AXbRoUWzw4MH2GhuZQto06Zc7R44caWXULrzwQtsMWKtWrViePHli999/f5rfR6k6Ss6GhHQd0qAodZm6pOOQIUNsI2XIKFlINSPSfdLbUBtdli9SpIhVhwoJm2rZvE3luU6dOsUWL15s6Rhly5aN9evXL83eMcmedsCGdcp8+xQxxiTSei699NLY3XffHX+/Py7du3e3NKiQymL6Y0XKLikYlPmmChQV6HiNPkykSoV0/vixhOqN9MehFCilU9nUTmW1aMohx8QfQ9IOKZgQGnoxULTGHzd/nlB4hd5UPAeFxP/+3Lt5niE9jGI+/J1qoR7HK/o8WKJEidjw4cNjoVNgkUb+HIMRD4iU5uNE4aGQaiwhDcxRxYsXt+Ai+gBEvW8ad7388sspjh+v837KZoaG84bKT+y1GDVqlD0YUia0WLFi8cEmxPMnqm3btrHq1atbdbXUx8P/vX379hbYh1TW0P+u1JDv2rWrBRc0WKTxEnXRQ8W4S6AAyjT37NnTxhcaUNLr5Pnnn4+/l/K8+fLlC2JfV3oob3n++efHDjnkEGvWxYPQAw88ENSEWBRjyUMPPRQPUtn7xn4lgg36VUQrFrIf5dBDD41XYQsJvzsPzr169UoxJr/wwgvW+C3EQJ39JFxHvjzzNddcY8GXnyjzE6/+eNHklXH778Dv8VBgkQ46JrJCwUYcmr55IT3s4NNPP7WyaalLxlJWlZkxZoKiHn/8cashHypmCbmxc0Nn0yTBF/WsQ+WvF/8n59FZZ521x3njffXVVzaYs1oYKm5YjD3c2ChX6I9dKDes6BhLoMUM87Bhw+xBkBWdadOm2deaNWtmm/u9t99+2womhIhjFg0cWDWl+MGGDRvir4cSWETPHzpq04E8iokxHpjpU8FmZY/JICbGQkV5XVaKWdWhXCql9slUYNY+xA3b9913nz3jgFV2Vk6XLFkSP6/osO3LyXKdqb/Z/6jcbCaRg+lzVEPIvfQomXrSSSe55s2buyFDhqT42tixY90zzzxjG74KFSqUolxfaFKXb2QD3JFHHml58pQw5k+fxxsC/7uuX7/eyn1u3LjRFS9e3L5GEQQ2lZ588sl2TpE7748f5xR5zuQ4hyj1eRT9PLTy1hRCqF69uhsxYoTlLW/atMn2v1WoUMGOw+mnn+6uuuqqFPtwQh1/PH87T+8cSnb+GiHnnXOFPSecOxTPOOyww1K8j2IS7G0qU6ZMUMcotejv/u2337qRI0e6d99911WqVMnVrVvXtW7d2oWIvTZsXp8+fbqrV6+eq1q1qhs6dKh9jdcHDx7s3nzzTXfIIYfYMfz444+tjLw4p8BiL0IecDxqoLN5iQGmQYMGrkqVKm7Lli1WbYRBmZrfOk7/J6TgITOoLMLGQIJTjg0VjghCf/zxRxuw2eTGpsq0ehHI/8YfNv4feuihLpTfd8KECVZdhQcdXqNYBAEqG9jZyE6wMWjQIKsXD113GaMoSbQYSbIHFhSKILA48cQT3YoVK2zT/8CBAy0QTYvuXymlnsQIbVLDTw5ec801Flxxr+KexQQhm7eZ1Lj88std7969NfakQYHFXviTpnPnzq5ixYpWJSE03Mj79u3rXn75ZWv4sm3bNnv9119/tTKGPPCEOPDsCwKx6IxZMvOBwaxZs+xBkBKYVMviz88//9xmCRm0qUbCbM/TTz/tWrRoEVxAsbeHGT/2fPLJJ/aQnezN3qLH45FHHrHzgxt3FOMMVWpmzJjhunTpYjf30M6bzPLHhSCM8YeGpSE8PLNCQbNAVim4X9HUjUa3zMRTpY+ZZjWbTJ+/l4f2wOx/7+g4xFjD/YkqWYzBrIaykvHee+/Fy6crKN2TAosMonF/YVFi7LjjjnNTp04Noi8DmOVhmY/a1gRUzDgTRLAEyPEqWbKkHQuWS0MbgLy9BVP+xk75UJbk77vvviB6MoB+A8yQ8jB85ZVXpnidrsBg6ZhglYCD9xGEhHC++P4UmcVDEnX1faneZEe6AbPNTFhwXviZdn8D53xh9rB+/fouZBmNP/5rpIYRjPqSqyFg8mLYsGGuR48e8V4CjDsffvih69+/v3v99detvxDlVSV9/hxaunSp3f9DQalqSutXrlzZVooJSBmPWB1l3OFrrGQwJmtSIx2xgKTeeE1n0rRKzqV+P5sGqfST7PzmrKeeesrKgpYuXdo2IFPpiM1ca9eujYXMb57d1y7a5cuXD6b8rt8g+u2338auvfZau8b8deS/Fr3OeB8bBJN902T0dx44cGDs9ddftwIR0WMTfY+/FseNG2cdlal4FArKWFMRi82QlPrOaNwJpZhG6o3X0So9aW2qjVZYO+ecc4I5ThR94LzhY8KECXt8ncpQkydPDmYje6JdpN99912rtBZKF2mKi1BKv1SpUlYIgkp0oMTs119/bVXXZO+CCiyipdWuvvrq2GWXXWa1rVevXh3/WuoKLHPmzLGyhpxUIaCHANUPCC4YhOnP0KdPn1iFChXseEnMbtS+UkZ6Nyh/s3/sscesMlRI5Xe/+eab2Jlnnmn1z1etWmWvpS5XGK1iQ/+Pbt26xZKZH094aK5WrVqKqlfRY8Nxid70CSp8qeuQcENnMocHRCZ2UlfnC40/J6i6R8lm+ngMHTo0zXPM/7lixQornxpahbXRo0fHqlatamVSOUaUBk1LKMFWIii1T0+dkHBfuvfee613GRUxCUR5LpLMCyawULO3jPmHvDVr1sRat26dYjUHn332mTVaSn0zC40ave0dteJPP/10q4tOv4Go1CVTmY2mPG96N/9koGZvGUv9gMdKjsdDMSumlCBm9n3ZsmWx0KjZW+aOz5QpU2xSA0zk0POEh0P65syaNSuYcs0ZXV9MkHIPpzcD9/q0Hpj9sxLNObnPbdy4MRbisaKUbJMmTWI5c+a0BoKs3oS+0pVZwQQWiTR7S+aHnihml4nQWQbk4RAMPP54XHHFFdaTQTM9avSWEW5MBKIPPvigzbhzc6IDsJf6eIQyG6Rmbxnjd+UGTuB+++23Wy+PaI19Vi9GjBgRC5WavaWPB75zzz3XJimiqXPc06688sr4yhcr8KFRF+m9HxuOwy+//JLmPYrGeJw/NLpN9kme/SWowELN3jLGbCAPwszysKLDjEbqZdEuXbrY30N7WFajt33HrOF7771nD4qkJdStW9dmfaKSfQZIzd4yv6+LdEvOkaZNm1oHWzpHJ/vem71Rs7fMI9Ai/TJ6HUWD1rReT3bqIp05BKRM7rAvJ7piipdeesmCMu7pCOWYJCKowIKLi6iT2bDUmFHlpuY36yCE6NRfJH5zFkEWs108ADEQsWmbPRb8ecIJJ8QvumR/IEx9fJjN4HyIzoYx0HBDZ/Vi06ZNKQZyzqdQbmTRc4jAgQdnrjWPv7/66qu2l4KPELF6M3v27NhVV11l4wwTHBQB8NcRKxkPP/xwiu8JYfzx58+RRx5pD8Pe4sWLbczh+iIg80Ka0PDnBg99jMkEn1w/qfdr8T42lfq9giEdo9TIhyf9tF+/fnb9pFWUJZR7V5S6SKd/32KSkBWLDh06WNEIjhMTgv48GTRokKUVSuYFFViAnGZydqnM4lcuGKhZRiVvNdSBmeVRv4GWGxk3qb59+9pyKIMMF53fPJk6og9lwzZBKYMOqzqkJDDLSm48S8p+JigqrWotycYPvv4aIu+7du3alsbDHoHohlvSEvxycwizPn4cGT9+vKWD8TtzTpAH7vOWCUhZmShZsmT8+0I4NlHz58+3zbbRtAxwjKpUqWKBe4j8tXXDDTfYih8FEYoWLWrV+iZNmpTu94V4/4pibCZw9w/O8n/V5Ro1amR/Z6WdVWSPc4nVLj9Wc/58+OGHsWTmrxFS43jGmTlzZnxCg3s8+ypYVeaYEYRNnz492KD0nwgusOBGTjoPeyp4WGTzNh/HHXdcfC9FaCcPgQIzGgzG0QGFhyDSx2699VaL5Bs0aGCVRkLhAwNmbhYtWmR53qTHMSgzODds2NDymAm8+NPnyIcQUHj+WmnevLmlz5HTzaoFx4RZaGYPmRELTfThjsCBKiNpHTtWAwnEmGkN7dzxx4iAkwdnZplTo9xsqLnxYBaZQIKHZPbdfPnll7bPjYIjrF7wIBQiP+68//77Nr5w/fBg7Msys1eHYJ5xO/r+UDEm88xDChRjst/Xxp9MjPnxKZRJDT/2cM9mfEl9jrC6zP2M8yi6kiqZE0RgwTIxGyfJlWNTKRiQmaG/66677Obl6xOHcmGlhfKODMbkd0eRHvXmm2/ajHRoGygJuvidyWNO/TpBKh+UJL7tttssTzPEChqk9PDwQxAKjgM3sC+++MJmnDl+BK2hpPZEMe4wgcHMV7TSmj92HCNuYqFjIzvpYMye+pQMHnpIG7vxxhuDnYlfunRp7JZbbknRR4CxhwfFiy66yK4t7muhaty4se2roFcQwSmryUz6sMLOTDOphyFKq2fQAw88YPuWCEjZc8K4Q5YGk6peCNeYPza//vqrPQPSesBLnToXDTZCD073RdIGFmr2tu+Y7aG8GlU00sJDM0FF6k3dyUiN3jLvtddes0CCQZkAtGzZsvG0ll69etlNnoZwIQ7Oava25+/nAyyq8BGEghQ5HgIZoym/yywiD4g8MPrVitDOHTV7yxyqh3HvYmWZKkasfLExmWCeilkUAwipj1AUD86+RDMZGYxBpNRxXZGuyoy8LzAS0mopSNUtXLiwfRCcR8ffUCoV/luSNrCAmr2lza/KsFGd4xLt6suGZI4PpWX5WggPPOlRo7e0UcnIHw9/Q6IiC8fiySeftCVkf5N69NFHU9TSD/FcUrO3/2F1i75ArEpQijj1hnVW/5hBpAQv6Zl+FSzUlWQ1e0spGkQx0ZXRAyAr7VxrrJaGuCqoLtJ78vclzg0+CLSYbKZIBJNAqSuGyj+TlIGFmr1lDpuUmLmgjCyzO1SuIV+VVYlKlSqlyC0M5cYVpUZve3rnnXfsZsWDMgFGtPoTqF7DAzSz0aTUsc+CvSkIYWZVzd4y5s8PHnbo4ZH6/Amdmr1l7voirYfUXEqEsueEe7oPMlJfg6RLsRoW4jFTF+m0n11II/T7Rdm3RLrlqaeeaiXAWfWKph7KvkvKwAJq9pbxjYsZCz6YEeNCotESM83UrmYQ4oMHav9QGCI1eksbFTJYyalYsaIVQiCAiD5AM0jz8Eg+L5u6Q6Rmb+kjmPApPow5PChHy3zzIO271YcQjKamZm9p8+Mt4w33JirysSLKJBgpTzxAR9N0/fspskFfhtCoi3RK3KvIwiBrhY3sBJrRY0BlKPpSkcrLaqn8c0kbWKjZ2//4iyeafsFAzDJxFDd3jgUPQcxMk4PIA6Svjx4qNXr7P5wb0Vm/jh07WjUs+ptQ4pGNpiDIIKWO/gN+BSeE2UI1e8sY1wjHiHHomWeesbQoylyyAkZJVYJ4VpfZr8OxC5mavaWPgiu9e/dO8RoNzLinMRbRR8dP8jD+jBw5MhYCdZFOH40kWZFgrCEoZUXdH5vohCCfM3noU6KS/dnw35KD/7gksWvXLpcrVy73008/uVKlSrlt27a5V155xd1///3u+++/dzfffLMrVKiQ27x5s73+ySefuHz58rndu3e7nDlzumR34YUX2sfSpUvdRx995JYsWRI/bjly5LBjED0W3377rb2/RYsWrlevXi7ZRc+fb775xi1btsxddtllrlixYvb1X375xX344YduwIAB9vm8efNcaPz50alTJ7d161b366+/2mtz5sxxp512mrvuuuvceeed50qWLOlCxDnE+fLII4+4du3a2WtcZxMmTLBjNGLECDtOYOjluguBv7Z++OEH98EHH7hzzjnHHXnkkfa1F1980XXs2NH99ddfrlq1am7RokU2NpctWzb+fSGaMmWKu/HGG13nzp1dly5d7LrjI3rOhHLv8r/n+++/b9cR9/YHHnggxXu4r3fo0MHOn+XLl7tQXXDBBXZ/f/LJJ+3+xTOON3nyZLsGL774YnfccccFd31VrlzZzo0jjjjC9enTx54JwdiTJ08e9/LLL7uzzjrLvi4JiCUhNXtLyUfdzHJRCSJ37ty21BetdJQelgajm2+TlRq97Z0/V9grwHFhZcu/Rp19Zp8plkAJQypFhUjN3jJGtR7SeXwlmihWdBiX2MAd2rWVHjV7S4m0Ju7hpLJENx9H72N+lZR7fygzzuoinTmkWHI8KCDBXjeuLbIz/NjNqpf2fSUu6QILNXvLGKUc2TTJ4MxGJfJVow/NnTp1it/0qfNM9awQNjKp0Vvm0bWeh2fyVTlufkmd84h9KBRGCG1vjpq97f3aojs9xya6byB18BBCSmFqavaWeZwv9DrheDBRSNpTqBXWPHWR3nfcs0jVZVM/z4M8L5JGR3ovNKmRmKQLLDw1e0vJDyJUQABBFx032YPCXpMPPvjAaqVzTDZs2BD/vuimymSlRm/7hgeckiVL2oNQ6v0FbFTm+gqZmr2ljZUsGkmm9VBD0BEtYRwiNXvLPIIJ7lusnNaqVct6WIT6oKwu0v8cz4OsVDDh/Pjjj8dfD3F83p+Sao9F1IYNG9xNN91k+agvvPDCHl//7bffLN+wYcOGrnTp0i4EPqc7mlc5evRo1717d3v9sMMOc9dcc43r1q2b5Rzmzp07mBxwzJgxw86J4cOH2/4J9gu8/fbb7phjjnG9e/d2GzdutNxUzplQcptT49zh3Ljqqqvc3Llz3dChQ13r1q3t9R9//NFy5Lne6tevn9R7CPzv9ueff7oCBQq46dOnuyeeeMLNmjXLrV+/3nK9Z86c6c4++2w7Nlu2bLHcZvbt5M+fP6jzxx+rO+64w82fP98+yGeGH4vYS1CiRAl33333uZCxF/CQQw5xixcvtr9zH2MsIk/+nXfesbGHfTqM1SH5+eef3cKFC+3YcD5xHLBy5UrXo0cP248yduxY16pVKxcSP45wb2LvH2PMuHHj4tdWdE9OdMwJafzZV6HtO/lXxA5yavb2z6Re6nvhhRfiS+2hHCc1evvn+P1Jm6MqFOX5yJ1nptV3Ug6Bmr3t+/XGuUKPhuiqH6uozMgvXLgwqGtLzd4y5sde30+IsaZcuXJW3YfVm+j9iveEUu47LeoinZhQV7v+LUmzYsEMKVWMihQp4ooXL+7OOOMMqwy1Y8cOq9DStWvXeJWWZJ5J3Vd///23rUxEMZvB8UnmY/Tuu+9a9aIrr7zSZt9r164dr/6ESZMmuebNm7tp06a5woULW3WNwYMH2+x8SLM9fvbm999/d2+88YbNoFIx49JLL7XZQyqMUdVn7dq1dg1S7ado0aJBzPr4c4QKWPy+n332WYpzSFKikg/XD5VXGIupXsP5w4w858xLL70U1LXl70P9+vWzSkdUD2vWrJmttFeqVMnlzZt3j3sV4xCvjx8/PumvL698+fLuiiuusOpY3M9ff/11O4c4Ds8//3yK1ZuQ7u3+3s11BVbax4wZY+dF48aN3eWXX+6qVKmS1T/mQcHfr5577jlXrlw5e36UBMQOYmr2ljmZmQEMMWJXo7fMozoYKxLMzJPTzAoFefGhU7O3zI050Q3r48ePt6Zm7CfgTxqdbdq0KahjpGZvmcN+reOOOy6eceBRWINVLjpwh0RdpDPHrwr7CmGZeS+d7lnxiRb9kX/moAss1Oxt3wagzKYV+ONKekuyNxRSo7fM8ecOKQdUxWLgpdEQmwSbNWsWq1atWqxly5bxzvYhUbO3zJk6dWrs2muvtU3bXFvRoItjFr3xh5ICFaVmbxnjIY+xJ61KRhSKYENySGOypy7Se/K/P9UsfSoq9yjG4Yz4cYcALfQJxGADC4+ZG2Z4GFg4ebzoBRa90HgoYjYolIvMXyzMbqVVMz7KD8xUP+IBO1rtJ1n5c4Ogghx4BmGqsjALVq9evdi4cePiFX1Cx/4bAs7o9fTtt9/Gy6eyouPz40PgrxdmlMln9jcyf6xKlSoVK1q0qO034QGRYxX9vlBy41khZjWQc6R9+/Y2G0iuPLOoIfPXEdcM/ZXS6qJNAMbKO/eskBG4c6/ngS91b5gmTZpYZ/vQqIt0xseGya5XX33VVrpYCcxo7PVjFVXFKCvvx2oJLLBQs7e988eBMmp+pjkzeKDmITvZqdFb5s2YMcNK7dK3gg2kqfFw9Nhjj8VCpGZvGaMk8dChQ+3vzMoze8rx4gZOfxzOrZCp2VvmkF5IoE4qJpOJTz/9tGUgMAnmi2+EkkIXRSqh77PkrzP4wggUS6AoQEgYb2vWrGkNbjk//PjrpTcOV65c2dIPJdDAIkrN3jLGAEx95mhknpp/nUotDN4hHR81ets7eptwbXFu0LH19ddfT/e9Idzc1ewtc0gPo3M96FLP+cOsIH8/7bTTbMIjhEmMjKjZW/oYi9k34K8p9ujcfPPNsWLFitlDIKuBrCqHGrRDXaTTRmVQenT5aoWsCi5btiz+dSahqfro91PyHMB7M7MfQ5I4sFCzt71jNpAVCKL31Mujaf2dZcPU5TKTnRq9pS31AzHLyzQPYoaVh0WOjV9eD5WavWWMfUmMxTz0sXLDueNXvHr16mVNBP2G3FAfDD01e0s59jLu0hiQNDpSwVil8Njkzwp89PiEupLjqYt0yvOHbBaCLQJTJi9IGyPNmckOJk6ZbGX1yx8bim6QwiqBBxbRwSR60dBVkhUMZn9YXu7fv3/8wgtt8CE9hWCLHExydQm2ojge/phw46c+eLRyS7LjvOH3bdSokS2Z+pUJXieX94gjjojXiw/t3AFV1khb4U9v8eLFsW7dullHYAohcH2Fdmyie5cI2qP9GPxYxOZtHp5D448NN2lSMPyMIEFEtL8Jey4efPDBWKjYuzV58mTbYBtdAeRBiJ5LTIg9++yzsVCxR4nKRgQUXbt2tfGZ+zkBV1RoY8/eqIt0LPbDDz/Y9RNNs+TvrLqzUkpaL8+H0YkxX1FL9p+DNrCIUrO3tLG5lKojbG4nKqfaCPsJopj56devXzBNl1JTo7e0sfmNHF4aTDL7E02l42GIByBSN0KlZm8p+d+TCmGsAkY3QbK5lJxnKom1bt3ajo8vLxvK8VGzt4z5FQiq8F1yySUp0lZI9+EY5c2bN3bGGWekaIIrGQtltcIj+4CUOcbk6DXEcZg4caJVNCT48q/JvyNpGuSF3Oxtb42B3n77bffUU0+5VatWWbMhmue0aNEi/vWtW7das7NkpkZv++avv/6yhm80oqJxGdcVTSZbtmy5xzkTUlMqT83e0ta3b1+3adMma0rKtcPvzzU3bNgwG4fy5Mnj2rZta8270hqvk52avaVv8+bNrlevXm7lypVu5MiR1uDW++233+z8ufvuu93o0aPd6aefnqU/a3YW4riDxYsXu1atWtl1RbNJriXGGK4jxp3UQru+DqjYQUbN3jL2ySef2F4JyswxUxg9Fmx2Y/WCjUuhUqO3fcO+JKqyXH311bYZkJWKefPmBTXbrGZvmTs+pPaQwtK2bds0z43UTc5Co2ZvGXvllVeswhFlVKNVjjzOKV/lKJSx55/wM/Hc7/3sfCiryOzlYiM76Zb0yfFYwQhlPM4ODooVCx9ZZjbC9BE7s0K0tL/22mtdMvMzf9OnT3c9e/Z027dvd6VLl3a//PKLq1Wrls2snn322fFZoUKFCgUVsfvf88MPP3QXXXSRW7RokStQoIB766233CuvvOKWL18eP09YqQiRv2beffddV6lSJVesWLEUX1+9erVr1qyZzQQ1bNjQTZ061YVm2rRp7tVXX7WVmqOPPtq1b98+fi199dVXrmTJku7QQw8N6tqK4vphNpnZ92effdZdeOGFQc/Ap/bRRx/ZMRk1apRr1KhRipnljh072iogKzshrZD6FeGdO3faebNgwQI7d8aNG+eqV6/uBg8ebH+GfP74Y/THH3/Ex5e9vffbb791p512mps9e7arUaOGC8UXX3zhZs6c6SZMmOD+/PNP17x5c3fHHXe4/PnzZ/WPFpbYQUDN3jKHRmWUVsP9999vsz/MylOej5nUTz/9NOjZHjV6yxibbdmUzfny1FNPpVkQgPPIN4QLIUdVzd4y5vOYffMyNvizSZIKR3fccYeNw+mVug6Nmr1lXGWNLu2ghDOzz+wLZCWHyj7RJpQhUBfpvYs+x6QeY9izdOedd9oeJioZUthHDpxsH1io2VvmjB492m7o/gZG5QO6AlOGrnTp0lYtizKhoVKjt71juZibe4cOHSy4oG9FtLoGNyqqQoVIzd72fOjxdd9JOaACHWWJvREjRlhlNY4T1xXVWkTN3tJCehPV+UhLjT4gMulD4E4BCR4QQ6Mu0hnz1wm9YEjVpUAEY7IPIkhJnT59ulWE8qXB5cDI9oGFp2ZvGePiohY66CB57rnnxmc3rrnmGntYXL16dZA3LqjRW+bR+4Xzif0UPBiecsopNgPG7CGlMkNb9VKztz0xttSpU8du4nSqv+666+KvR7FqQfnHkIN2NXvbO+5N7FMiuPD3qWiPBla+Qjs+6iKdPv+7L1261MZfgi6CCMYayltHcT75xpOh39sPlIMisFCzt8xdaJSXxU033WRLy9GZ5rRSW5KdGr1lHhtKST8gddD3riAwp7vrtddea+eUbxgY0s0dava2J64b+nXw0EPaU7QAAscgGmBw3fnjEkpAqmZvmcPv639/ukYTpD7yyCNZ/WNlG+oinTHG4ltuucX+vmTJElsl9Ss1jEkUs5ED76AILNTsLXP8MSBlg4ZCDz30kO214MYf4kwz1Oht7w8/BBTsF2BQpns9M9FUqFm3bl0sVGr2tnccFzr88sEsKekI0YceHhh5EAotPz5Kzd72lDr4jv7urIAxBjExyPkT6gyzukjvHePKOeecE/99mVDmeQeM1xwvrjk58A6KwAJq9pb2QMwDM2k+5Of6AZvXyM3kZs9A9MQTTwQ1mxqlRm97P4fIx2XfAOcQ1xkrOdysmJEOkZq9ZcyPI6weM9bS1IwCCKRfcq2xikPQwVjMXq/QqNlb5lCWmPLfFNQg8KK4CPt1WF0/77zz4sVGQqUu0nvHcw7nDqm7rAj6sZgVG1YJeTYKaWzOLrJlYJHRSUANfapnVK9e3Wai6aQY5XPpQrixU0OfB0ByDHPmzGmbSH0VLN5DF+DoRuUQLy5ydD/66CMLKnjoOemkkyy9J63zJcTjQ7UjblCpf39mVKkn/+yzz8ZC1adPH9sj4K8njg8pT6xwsQTPhtPJkyfb10OpfOQfmnlI5tyJ7tvioZkZViZ/ChUqFCtTpkw8LzyU4xPt/0KAziRY6r1+BF0USeC6i3bcDoG/d3EdUXCENN0WLVrYfYwZZ84dgi4eqHkwDDm4UBfpvaNADRX6OF/8BCGpl0xCs5IqWSNbBhaemr3teTwoxedx4yYNg1keBhjSWUh7ogICN3z/oBjiA3NqavSWNlZtmIFfvny5fR4NRHkoYiUjJGr2ljE/BrPvhn1Kqcsz84BDqiEbKefOnRvs9aVmbxljctA/CPoxh/OGSSBy40mhI3inKEBoQanf10XGASvtmzdvttc4DgQZaQnhHPJjD2lO0b0TBFik77K6TJoYxUZ4NvRjU4jnT1bLdoGFPwkIJCgNyiwGufBcZO3atYvfrPzDYigXFr8fubmUjeVCIm2F/SapV2iYBaK8LLM+5M6HJroRMK09AtSP54GIPF4GodBxHtGFnJmx1Mhf9ZXGQkMlNWbBCNRZZvc391DGm4yuLW7q7BWgIos3aNAgK5vK2JQ6Lz7EFDG89957FpwWLFgwVrduXXtoDu2YpHVvJzWX+zoTPR5BVupgnUkPuiizMh8adZHek/+dO3bsaOOz32tLoPHhhx/apn/6wTAW+SpiIV5n2UG2Cyw8NXvbE0t8bNbKnTu33ahY6vOVeqIDDQMPeavRG39I1OgtfWndkFjtImjlg5v4a6+9ZkvJ7B/ws6oh3MjU7C190WuEFVHSLv0+AhqXsvGfa44HRr/6FSo1e8v4PGJyzAcLFBVhVZT7O3t0UjfA5TzjQTJEFEKgylONGjUsbY7noRCL0kTHH9LDCLYI2v1rrO6oumP2ki0DCzV7y9hnn31mm5aYUWUjV3Q2I3WgFVLg5anR294fDgmumAmjhCFpCaQW+hs81xuvk8eb+vuSjZq97TtSe0g3INDiYZDr6d1337WvMfnD+B0qNXvLGKtdpOwSUHBvp4w1JWa5xshQYL+Fv2exgkGFxxD2oaiLdOY0aNDAJjLAOMwqBXsscuXKZfcxjl0Ik2DZXbYMLNTsbU9+sKHqAw+BXFTkMTPLzEMPe1FCzftOjxq9pY0KPuSjMhCz2Zbri4GZVQrSC/0ycijU7C19pDZR/SqKMYgVZRq8cdxYtQCzqezXIY011GsLavaWPppKco5wnZHiTOlmX3qXiQw+j/ZgCGUmWl2k9457Eyt/3LNAmiGTYwTsHDcKs/j7umStbBlYqNlb+mgSSD68TwXjZk5ZRx6WmfGh4lGoN3So0dueOB7MePkHGtLofKdfn65B3jNBarTRWSjU7C19I0eOjF8v5MRHS3yzZ8BPZjBTz2QQqz2hUrO3zKf4UK6ZiY1oxSwCDR4WQ5owhLpI79ukmG82STaCD0q517MaSOAuWS9bBhZQs7f/8QMIVTSYKYzm6PqvsYLB5nZmykKjRm97H4zZj3PppZfabDsb3FI36CJAZfaHpeYQ9xGo2VvGCK78vi4elqMPNQQXBK6M02yiDCloV7O3f84fD7qP09iWZoK+EWWIx0pdpPeO5xwmwdh7Et3LxZ5S7v2SPWR5YKFmb5lHSk+0/Kc/djwI0n2S2cRoaboQqNFb5hCMk0ZIsEVOKkFo6ps3aS9sEgwppU7N3tLGKhZ57x7HhxQnbuCkHJx11lkpqs6x0Z0SvSFN+ESp2ds/xyQHqxch7OlKj7pI78nfn0ghZFWZQCJaCdSnOzNOMTb7qmshnj/ZTZYHFmr2tnf+d2Vw4SYV/d25+PicGxvdyEOlRm+Zw1Ix5xD58dG0MIIxHqYpYRzKjKGavaWP2XZSMaj05Jtw+VQwxmpSUklHYLMts6tRoYzNava2f/DgyN6L0KmLdEr+92RPLceD66hevXpWTpbnQfAnAZdPjw/hvnUwyLLAQs3e9h2ROZtu/cygRz1nltz90mCIx0iN3jKPwZeZMcoYkr5CQMYMdPv27eMlV0MYoNXsLX3MBFJ2mM2ifoUrmlLIDZ20OtI3SNnwzSZDpGZvsj+oi/T/+HGWsrIFChSw1VEmeygkwbEge4MVdoIuP7ka/T4JMLBQs7d/hguI3G8q+HCB8cBDbjMPiKxmhLwMqEZv+45BmYcerjECeV+BJaSgQs3eMsakBZM7POwcddRRlgsfxSZlUsdCo2Zvkgh1kU5f9BmGLAw2s0eRhUD1MFIyr7rqqhSV1yR7yMF/XBZYu3at69evn3vqqadc7dq13fr1690TTzzhzjvvPLd7926XM2dOe99ff/3lunbt6q655hpXtWpVFzqOzQsvvOAGDBhgx6x48eKuUaNGrkePHi537twpjl0yS+v3fO+991y7du3s7/fdd587/PDD3dtvv23n2Pfff++OOOKIYI7Pvvjuu+/c008/7fr37+9CsGvXLpcrVy77++233+7WrFnjpkyZ4latWmXnyujRo12VKlVsjHr11VddpUqVXEii18jZZ5/tKlas6PLly+c2b97s3nrrLVegQAH34IMPussvvzzF8Qzt2uL3Pvroo93gwYNd8+bN3c8//2zX0eOPP+6qVavm+vbta/c2j+N17LHH2vslbP5a6dSpk11XN954o6tZs6bbsWOHW7p0qd233n//fVenTh3XsGFDd+KJJzIJ7HLkyOFCwVgzatQoOyY886T+3R977DE7TpMnT86yn1HSkdWRjZq9/XNE6tFOnCHMNEON3v49oR0jNXvbkx9nWeWjYIYvt0vON7OFZ5xxho3XrHLR0yLUcVnN3uSfUBfptLHPjT0mHisV7I/kGPG6b0EQ5VdwQrtvZXdZMr30999/258rV650n376qXvooYfcyy+/7L744gtXq1Ytm43ftGnTHhFqSNF6ZpQpU8blz58//nkos4V+tnnIkCE2y37ooYe6GjVq2ApO27Zt3Z9//um+/fZbm/F44403XNOmTVN8n6QvmY/R+PHjXZs2bVK8Vr9+fffbb7/ZzPz27dvd/fff784880z7OysWRx55pL0vixZ2swTjLLPxjMHMorJCAVYAL7jgAtetWzebqee68+8PUalSpdwvv/xiKxGXXHKJrXixUnrddde5u+++28ajrVu32nsLFy7sXnnlFXf66adn9Y8t2WSM7d27t61UsCrBWDNw4EDL2DjllFNcs2bN7DmJlY1QcC2dfPLJ9vdPPvnE3Xvvve6rr75yF154oa2Q9urVy82cOdNWeDyyNJL9vnVQysqoRs3eZF+o0ZskQs3e9g17Tdh/woxqFMeHqn3+9VBWStOiZm/yT6iLdPrWr19vBUVYPX777bfttRkzZsROO+00qw7VrVu3eMVQyZ4OeGChZm/yT6nRm+wPavaWOaQ+NWrUyK4nNh3z4MyxIpinXHG08lro1OxN9pW6SKePClBUUqMwzR133GHFWfD4449btdBoypRkP1m2ebtJkya2GZvlrv+/cmJL6iz/TZ061ZbgSUM47LDD7DW/5CVhY4MkaQbLly+31LnLLrvMjRw5MkUaGCkvFAaYP3++pSBI2NatW2dpKKSoYOfOnbakPm/ePPfmm2/apv7OnTu7//73v/b1JUuW2LJ8gwYNgtswmdqiRYtsjF69erVdS998842lRt10002uS5cuKTbCi3OzZs2yDaeMS6Rg6vhIen788Uc3bdo025x88cUXx4tEMBZx7+LaCxnXzosvvugeeeQRS7sk5ZDiLDwPFipUyK6r0Mfn7OqABxb+RLjhhhvsJjV79uz4iUE+IX+nAhRVNajYIpKWxYsXu7vuussqaFxxxRX2QX7q119/becWOeDPPvtscJVqZE9Uebr22mvdGWecYbm6/AnymufOnWtBB+dT9erV3Z133mljj6cb1/956aWXLNjatm2bVTryx1DHJyWqGLI3pWjRoln9o0g24u9DnB/sLWWitGTJkvaA7P366682qXrPPfdYNTrGIwWmzv3xxx+275ZxmgCD+3rZsmWz+seSDGTZigWzzGzG4abPzKBHlF6vXj3bvEMErxuXZDRYU2ru4Ycfdr///rvLmzevO+qoo1zlypXdo48+ap8rsBBu2B988IEbPny4lSdkNpkAo1ixYvZ1Vr+Y4JgxY4a9j5s7Y5CkLM2bmsZmkczx18qtt95qYw3BxVlnnWWrpGxOPuGEE2wcGjNmjD00t2/fXveuVJiIHjFiRDBl0Q9mWRZYcNFQoWXChAmuZcuWlhr17rvv2gziqaeeag8BitYlszMaBBLDhg2zWSDfh0ADs0QxafH8889bnwHSLG+77Tab3PAYfz7++GPXsWPHLP05szNdUyL/LKhYsGCBVaHjmYdJDe5XjEncq0jzufTSS13BggXtvXwocE+fng2ztywLLKBmb7I/hdboTfZOzd72Lrq/bW972fxxGTt2rO2RI11DRPb+AMzk14YNG1yfPn1S7MlhDwFpmTTB4++UkRc5mGVpYBFF91vyUn1fhpBu7LL/aUZDog/N7J2YM2eOdWcnmCB1jrQn+lYwk0gflOeee84df/zxmiXcyzXFqg5BGn8SqIlIxtRFWkKSbZ7cQ232Jv8OBRUCNXvbk59LYvbUV1EjoKJaVmauKVLISGNVUCGSNjYYEyx4pHgTULz++uuWivnDDz+keD/X1KRJk+zvjFciBzM9vYtIUuOBmA397K9gdSKK6kZ0Q+7bt689KIfQ6ZbgiY2id9xxh5XcZTWnQ4cO8WIHaQUipEn5IISu9nQNFpG0qYu0hCzbpEKJiPxbSH1q1aqVPThTLIKqTyVKlLAHZR6weVhm42QoqExz4403uj///NNKYJLrfdJJJ7k8efJkmEp47LHHWv8KqtuISMZYFSRtkCCDSk9UgmLVgl5MW7dutQp1jRs3drVq1crqH1Vkv1FgISJBULO3lEgPK126tDvkkEOs3OWVV15p6WE+xYmHIspfEnixysHDEPX1P/zww3gAIiIZW7hwoe3l4npiQoPxpkKFCu6JJ56wcYdy6aRCiSQLBRYiEpTQm735whjsqSD3+7TTTrMHHLqQsw/l6quvtmpPPXv2dMuWLbNUDmZXzz33XHtAivYdEpG9UxdpCYkCCxEJgpq9/e/3pGM9M6bU0ve/N1Vp7rvvPivbTJ8PSmBSOYvN7WCl55hjjsni30Dk4KUu0hICBRYiEqSQS1pPnDjRUpw+//xzd8QRR6QIrFjRoSwmG95pVpqZ/hYiknnqIi3JTIGFiCQNNXvL/MwpKWDNmjVz3bt3D25/iUh2oWtPkk2Y03UikpT8rPveggpu5gQVNHmj1Ophhx3mklnq+SPSMC699FI3ZcoUq4jFfosvv/zSrVixwlYzROTAUFAhyUYrFiJy0K9QUHGlSJEiVj6WHgtsOqYvw94wa0+6D/sNkplfnZkwYYJbtWqVpUDxOU25CDKoDsWeCpqUUiGKTsEiIiL7SomzInLQN3sjV5kqKzR7u+uuu+LN3lLvoSAQYbWCFQ3f7G3atGku2XEctm/f7p555hn7/elHQVlZUsbYlN21a1dLBSNFiq9BKRoiIrKvFFiIyEFtzZo17t1337UmbzR7q1u3rv2ZVrM3AhGfJsXeAj6KFi3qkh0BFceDPhSsSnjvvfeeu+SSS6yXhQ8oPAUVIiKyr7THQkQOaueff75bvHix27Jliz0Md+rUyT399NNu5cqV9nVeI1WKGvI+85Nmb1RDohtuMmPVxgdUfPz00097pILRGO+5557Lop9QRESSiQILETnoH5wLFizoJk+ebHsHqAtPahTpPbxGX4bbb7/dHp55uKbZ2+zZs91DDz2U9B2kfSrYgw8+aF21+aAhHt2AfZDVokUL22tBZ3IREZFEaPO2iByU1OwtYz4FjOMyZMgQd9NNN1lnbVYpRo0a5dq2bRt/b8eOHe09IiIiiVBgISIHNTV7Sx/HggCKIOuaa66xilmvv/66W7Bgga329OnTx91www0WcLG6EXLTQBERSZzuICJyUGPzMaVmmZmPpkehSZMmrmXLlhZUIKSgwm9sr1Chgrv44ovdb7/95gYPHmzBBMeBKlGU5X3ttdfiwYSCChERSYTuIiJyUFGzt8wfI44N6WBTp051N954o+2xaNCggX2Nfhbz58939evXT/E9IiIi/1RY03cictDzqU6pm73RRfuUU07Zo9lbs2bNXEiiqWDsLxk4cKB9fPbZZ3bM8NVXX1n1rIsuusgdd9xxSoESEZH9QnssROSgQxoPKVDRZm9LlixJs9kbs/bJ3uzNBxObNm1yhQsXthWKe+65x4KtP//80wKL0aNHWxDBe3g/QceMGTNcgQIFFFiIiMh+ocBCRA4qDFk8CNMEL61mb6Q/+XSfkJAG9vDDD7s2bdrYKg2pTzQAjB4fAol8+fLZSs65555re1OSPegSEZEDR4GFiBwUorPq/J29A+XLl0/xHiocMUM/btw4Fxq6al9//fW2MXvbtm3urbfecieddJJWIkRE5IDRHUdEDgpq9pYxVmvYb/L7779bWtRdd91l/SoIwDy+RldyaE5JRET2NwUWIpLtka4DSsqOGTPGNWrUyFYlPvnkE6v+5Dcrn3322e7mm2+2RnChoV8HKU1PPvmkNQOkG/m9997revToYasZ69atsw3bvhGeP2YiIiL7i1KhROSgoGZvaUv9e7L3JE+ePPb36dOnu379+rlff/3VNmt///33tsJTrlw57a0QEZH9ToGFiBwUqPjUunVrS3XKmzevVXx68cUXbaP25s2bXdu2bS09qn379i5EVH0iaDj88MOt0zjHygcOzzzzjAUgVapUcXXq1FFQISIi/woFFiJyUJRS3bhxo+2p6Natm21M5kH5pZdesvcsXrzYNWzY0FYvKKka7eUQwmrFCy+84G677TZXqVIlC7ooKVuqVCl33XXXWdoYQjkmIiKSdRRYiEi2lfphePLkySmavfHQTLM3HqBJ72H/RSgpUFEcB1Zrbr31Vrd+/Xo3bdo099prr9kqz+mnn26rOKeeempW/5giIpLkwrr7iki25+c6mHUnqKDZW9WqVW1z8nnnnWcfNIEjwKhWrZpr0qSJBRJPPfWUCwkBFKiAVaZMGVehQgX7vGjRolZ29oEHHnBXXnml++ijj9zjjz+exT+tiIiEQCsWIpLtqNlb5tCz47LLLnMffvihldpNK4CYM2eOO/74423je4irOSIicuAosBCRbEfN3jIfWIwYMcK9+eabtnJx0UUX2XGrXbt2Vv9oIiISIAUWIpItUSKVfRNsRq5evbql9dSvX9+VLVs23uxt4sSJtpoR+sZkVng4FgQYPmWMKlkcPxERkQNFgYWIZDs8HDMbz8oFs+9dunSxdJ+zzjrLUn7YkExqFOVVv/zySxeqL774wvZU8AEa4z3//PPu008/dVu3brXVDG3aFhGRA0WBhYhkG2r2lrG///7b0sPYNzF48GC3bNkyt3btWuvl0bVrVwvCeA/9PQgyfJdtERGRA0GBhYhkO2r2tqdoulfx4sXdVVddZb8/FbL69u1r1Z8effTReINAH5Rpw7aIiBwoCixEJFtQs7fMYaVi1KhRbunSpSle79+/v3viiSdsZYc9KSIiIgeaprFEJFvws+rjxo1zPXv2dG+//bYbP368u+GGGyyI6N27t23UXrJkSbBBBQi2WMnxc0Lbt2+3P1u1auUKFizoPv/88yz+CUVEJFQKLEQky6nZW+bRFHDBggXu2Weftc/z589vf5YuXdqVLFnS9lyIiIhkhdxZ8n8VEUm1WkEVqF69eln1J/ZM0JPBYz8FHzVr1rRmbwhl74DfQ7Jq1So3f/58C7BY0aGBIIEYKzolSpRwEyZMsMCLVKjQ08VERCRrKLAQkWyDYIJUH6oaUS41dbM3+jN4IQQV8BvTW7ZsaXsnatSo4W6//XZLe5o7d64755xzLCgj8GL/BZu5ffUoERGRA0mbt0UkW1Gzt//xqzJPP/20ldplfwmldr0VK1a4zZs3uz/++MM6kxcpUsRe12qFiIhkBQUWIpItqNlb+po0aeKqVq3q7r33XgsaCDj8SsZLL71kKxkhBl4iIpK9hJFLICLZDuk6oNnbJZdc4i6++GJ3zDHHuMaNG1sPi1q1arlBgwZZX4YzzzwzyKDCz/uwSsH+Cr8SQVDB3gs+pzu531chIiKSlRRYiMgBxwOx3wPQokULm20n1WfKlClu/fr17uyzz3bDhg2z9zRv3twNGDAgRfWoUPh0Jjats6Iza9as+NcILtjoPmnSJNewYUN7TQvQIiKSlZQKJSJZRs3eMoeAqk2bNlb5iU3cpEa9++67tnmblZzhw4cH04FcRESyL61YiEiWUbO3zGED99ixY91zzz1nx+SWW26xoIJO5E8++aS9R5u1RUQkq2nFQkSyzHvvvefq1q3rRo8ebTPyUWeddZbtu+jatWuW/XzZ1Zo1a2yTu2+OF0pPDxERyd4UWIhIljZ7e/DBB21vBfsqos3eevTo4X766Sfry6DyqSIiItmfOiiJyAGjZm8iIiLJSysWInJAqNmbiIhIclNSrogcEH4PwOzZs127du0sqCBoID0KlSpVct9//70rW7ZsPKiAggoREZGDgwILETkg1OxNREQkuSmwEJEDQs3eREREkpv2WIjIAaVmbyIiIslJgYWIZElw8cILL7gBAwa49evXu+LFi1uzN0rMUgFKfRlEREQOPgosRCRLqdmbiIhIclBgISIiIiIiCdO0oIiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIJIWyZcu6IUOGZPWPISISLAUWIiLyr/juu+9cjhw53CeffJLi9bZt27rGjRtn2c8lIiL/DgUWIiIiIiKSMAUWIiLyj82cOdOdeeaZrnDhwu6oo45yl1xyifv666/ta+XKlbM/Tz31VFu5OPvss929997rxo4d615++WV7jY958+bZ+7p27eoqVqzoChYs6MqXL+/uuece99dff6X4/73yyivu9NNPd/nz53dFihRxl112Wbo/28iRI+3nmjNnzr96DERE5P/k/v9/ioiI7LOtW7e6zp07u5NPPtn98ccfrlevXvawT/rTokWLXM2aNd2bb77pqlSp4vLmzWsfX375pdu8ebMbPXq0/RtHHnmk/XnYYYe5MWPGuFKlSrmlS5e666+/3l6766677Ouvvfaa/ds9e/Z0zz77rNu5c6ebMWNGmj/Xww8/bB+zZs2yn0FERP59OWKxWOwA/H9ERCQAGzZscEWLFrXA4NBDD7VViyVLlrhq1aql2GOxadMmN23atAz/rUceecRNnDjRffTRR/Z5nTp1bCXjueeeS3fzdseOHd3PP//sxo0b52bPnm0BjYiIHBhasRARkX/sq6++slWKDz74wIKK3bt32+urV692lStX3qd/a9KkSe6xxx6zVCpWP/7++29XqFCh+NdZBWEVIyMDBw60VRSCEYIQERE5cLTHQkRE/rFGjRq5jRs3uhEjRlhwwQdIU9oXCxcudC1btnQXXXSRe/XVV22Vg5Sn6L9ToECBvf47devWdbt27XIvvPDCP/htREQkEVqxEBGRf+TXX391K1assKCCB3rMnz8//nX2U4AH/SheT/3aggUL3LHHHmvBhPf999+neA/7ONiI3a5du3R/JvZTdOjQwTVs2NDlzp3bdenSJcHfUkREMkuBhYiI/CNHHHGEVYIaPny4K1mypKU/devWLf71YsWK2SoDlaNKly5tlZwOP/xw2wvxxhtvWFDC9/Pa8ccfb9/PngqqPrFRe+rUqSn+f71793bnnXeeq1ChgmvWrJmlSrF5m2pSUezF4PULL7zQggv2XYiIyL9PqVAiIvKP5MyZ0wKBjz/+2FWtWtV16tTJDRgwIP51HurZM/H0009bpaf//ve/9jr7JCpVquRq1KhhG73fe+89d+mll9r3s9rARm9WMCg3G0W52hdffNFNnz7d3nPuueda5am0UAKX4OTuu+92jz/++L98JEREBKoKJSIiIiIiCdOKhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIJEyBhYiIiIiIuET9P15pPRnioiUlAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "os.makedirs('reports/figures', exist_ok=True)\n",
        "\n",
        "ax = results_df['f1'].plot(kind='bar', color=['#4f81bd' if i=='baseline' else '#f28e2b' for i in results_df.index])\n",
        "ax.set_ylabel('F1')\n",
        "ax.set_title('F1 by attack')\n",
        "plt.xticks(rotation=60, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b12a2065",
      "metadata": {},
      "source": [
        "## Qualitative examples\n",
        "Before/after comparisons (oracle and pred-guided).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "7a71cba2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Attack: char_typo_oracle ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO ThRMA/I-ORGANIZACAO CÍVLE/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CUSROS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PAzA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALiSSON/B-PESSOA cILVA/I-PESSOA BATISTl/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acrdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [33, 38]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: char_typo_pred ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍEVL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 2050110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CRSOS/I-ORGANIZACAO E/I-ORGANIZACAO ONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSS/B-ORGANIZACAO ESCLOA/I-ORGANIZACAO PRAA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LwDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILAV/I-PESSOA BAToSTA/I-PESSOA DE/I-PESSOA MOqAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORÊA/I-PESSOA LIMA/I-PESSOA Acódrão/O x./O :/O 108226/O CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [33, 38, 55, 56, 57, 58]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: boundary_oracle ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA [MASK]/B-JURISPRUDENCIA 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA [MASK]/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [20, 33, 38]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: boundary_pred ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA [MASK]/B-JURISPRUDENCIA 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA [MASK]/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [20, 33, 38]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: context_distractors_oracle ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O ruido/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO lorem/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O teste/O 20150110436469APC/B-JURISPRUDENCIA teste/B-JURISPRUDENCIA 0012843-03.2015.8.07.0001/I-JURISPRUDENCIA xxx/O Apelante/O (/O s/O )/O lorem/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO ruido/O Apelado/O (/O s/O )/O teste/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA teste/O :/O ruido/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA teste/O teste/O N./O :/O 1082726/O ruido/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [20, 21, 54, 55, 56, 57, 58]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: context_distractors_pred ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O lorem/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO xxx/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O teste/O 20150110436469APC/B-JURISPRUDENCIA teste/B-JURISPRUDENCIA 0012843-03.2015.8.07.0001/I-JURISPRUDENCIA xxx/O Apelante/O (/O s/O )/O xxx/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO ruido/O ruido/O ESCOLA/B-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO teste/O (/O s/O )/O teste/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA lorem/O :/O teste/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA xxx/O teste/O N./O :/O 1082726/O teste/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [20, 21, 32, 33, 34, 38, 54, 55, 56, 57, 58]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: synonym_oracle ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Decisao/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [33, 38]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n",
            "=== Attack: synonym_pred ===\n",
            "Example 0\n",
            "Gold:      E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/I-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/O Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Baseline:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Acórdão/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Attacked:  E/O M/O E/O N/O T/O A/O Órgão/O :/O 8ª/B-ORGANIZACAO TURMA/I-ORGANIZACAO CÍVEL/I-ORGANIZACAO Classe/O :/O APELAÇÃO/O CÍVEL/O N/O ./O Processo/O :/O 20150110436469APC/B-JURISPRUDENCIA (/O 0012843-03.2015.8.07.0001/B-JURISPRUDENCIA )/O Apelante/O (/O s/O )/O :/O BRASILIA/B-ORGANIZACAO CURSOS/I-ORGANIZACAO E/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO GRANCURSOS/B-ORGANIZACAO ESCOLA/I-ORGANIZACAO PARA/I-ORGANIZACAO CONCURSOS/I-ORGANIZACAO PUBLICOS/I-ORGANIZACAO LTDA/I-ORGANIZACAO Apelado/O (/O s/O )/O :/O ALISSON/B-PESSOA SILVA/I-PESSOA BATISTA/I-PESSOA DE/I-PESSOA MORAES/I-PESSOA Relatora/O :/O Desembargadora/O NÍDIA/B-PESSOA CORRÊA/I-PESSOA LIMA/I-PESSOA Decisao/B-JURISPRUDENCIA N./I-JURISPRUDENCIA :/I-JURISPRUDENCIA 1082726/I-JURISPRUDENCIA CIVIL/O E/O PROCESSUAL/O CIVIL/O ./O\n",
            "Changed positions: [33, 38]\n",
            "Example 2\n",
            "Gold:      CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Baseline:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "Attacked:  CITAÇÃO/O REALIZADA/O APÓS/O O/O DECURSO/O DO/O PRAZO/O PRESCRICIONAL/O ./O\n",
            "No changes on gold spans.\n",
            "Example 5\n",
            "Gold:      MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Baseline:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "Attacked:  MANUTENÇÃO/O DA/O SENTENÇA/O ./O\n",
            "No changes on gold spans.\n"
          ]
        }
      ],
      "source": [
        "SAMPLE_IDXS = [0, 2, 5]\n",
        "\n",
        "def format_tokens(tokens: List[str], labels: List[str]) -> str:\n",
        "    return ' '.join(f\"{t}/{l}\" for t, l in zip(tokens, labels))\n",
        "\n",
        "\n",
        "def show_examples(attack_name: str, sample_indices=SAMPLE_IDXS):\n",
        "    print(f\"=== Attack: {attack_name} ===\")\n",
        "    atk_tokens = attack_runs[attack_name]['tokens']\n",
        "    atk_preds = attack_runs[attack_name]['preds']\n",
        "    for idx in sample_indices:\n",
        "        orig_tokens = base_orig[idx]\n",
        "        gold = golds[idx]\n",
        "        base_pred = base_preds[idx]\n",
        "        attacked_tok = atk_tokens[idx]\n",
        "        attacked_pred = atk_preds[idx]\n",
        "        print(f\"Example {idx}\")\n",
        "        print(\"Gold:     \", format_tokens(orig_tokens, gold))\n",
        "        print(\"Baseline: \", format_tokens(orig_tokens, base_pred))\n",
        "        print(\"Attacked: \", format_tokens(attacked_tok, attacked_pred))\n",
        "        diffs = [i for i, (g, a) in enumerate(zip(gold, attacked_pred)) if i < len(attacked_pred) and g != a]\n",
        "        if diffs:\n",
        "            print(f\"Changed positions: {diffs}\")\n",
        "        else:\n",
        "            print(\"No changes on gold spans.\")\n",
        "\n",
        "for name in attack_runs:\n",
        "    if name == 'baseline':\n",
        "        continue\n",
        "    show_examples(name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f609461",
      "metadata": {},
      "source": [
        "> Note: for true insertion attacks, the attacked sequence is longer than the original. We therefore inspect examples using\n",
        "local windows around mapped entity positions (rather than printing full token/label pairs 1-to-1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91382d0b",
      "metadata": {},
      "source": [
        "## Ranking: most damaging attacks\n",
        "We rank attacks by `delta_f1` (lower is worse) to highlight the model's main vulnerabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d4d491",
      "metadata": {},
      "source": [
        "## Discussion\n",
        "- Oracle attacks (gold spans) are worst-case and show maximum vulnerability when anchors are known.\n",
        "- Pred-guided attacks are more realistic; still reveal sensitivity to anchor corruption and boundary changes.\n",
        "- Typo and insertion attacks hit entity anchors hardest, aligning with robustness drops under character noise and insertion.\n",
        "- Boundary perturbations hurt because punctuation/structure act as delimiters (as seen in interpretability).\n",
        "- Context distractors dilute anchor focus, mirroring robustness collapse under word insertion.\n",
        "- Synonyms are mild: semantics preserved, matching small robustness drops.\n",
        "\n",
        "Hardening ideas: targeted augmentation with typos/boundaries/distractors, adversarial training on anchor corruption, and exploring char/byte-aware tokenization to reduce surface-form brittleness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fc4fdd",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. Character-level and contextual attacks significantly degrade both confidence\n",
        "   and structural integrity of entity predictions.\n",
        "2. Boundary attacks cause a small but consistent degradation, stronger under oracle spans; synonyms are nearly unaffected, confirming findings from robustness and interpretability analyses.\n",
        "3. Word insertion does not fully erase entities, but:\n",
        "   - disrupts span boundaries,\n",
        "   - reduces confidence,\n",
        "   - and breaks alignment assumptions used by standard NER evaluation.\n",
        "   - Note: this insertion protocol differs from Stage 2 ‘random word insertion’ (global clutter). Here we insert locally near spans, so overall F1 degrades less, but span recovery/retention reveals structural fragility\n",
        "\n",
        "Overall, the model is **semantically robust but structurally fragile**, relying\n",
        "heavily on clean token order and stable boundary cues.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
